{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a04146",
   "metadata": {},
   "source": [
    "# 🎲 Gaussian Naive Bayes: Probabilistic Classification Explained\n",
    "\n",
    "## 📚 Complete Guide to Naive Bayes Classification\n",
    "\n",
    "### 📖 Table of Contents:\n",
    "1. **[🧠 Theory Foundation](#theory)** - Understanding Bayes' Theorem\n",
    "2. **[🌸 Dataset Introduction](#dataset)** - The famous Iris dataset\n",
    "3. **[📊 Data Exploration](#exploration)** - Understanding features and targets\n",
    "4. **[🎲 Gaussian Naive Bayes](#gaussian)** - Probabilistic classification\n",
    "5. **[📈 Performance Analysis](#performance)** - Evaluation and insights\n",
    "6. **[🔍 Probability Insights](#probability)** - Understanding predictions\n",
    "7. **[🎯 Key Takeaways](#conclusions)** - When to use Naive Bayes\n",
    "\n",
    "### 🎓 What You'll Learn:\n",
    "1. **Bayes' Theorem**: The mathematical foundation of probabilistic classification\n",
    "2. **Naive Assumption**: Why \"naive\" independence assumption often works\n",
    "3. **Gaussian Distribution**: How continuous features are modeled\n",
    "4. **Iris Dataset**: Classic multi-class classification problem\n",
    "5. **Probability Interpretation**: Understanding prediction confidence\n",
    "\n",
    "### 🧠 Core Mathematical Concepts:\n",
    "- **Bayes' Theorem**: P(class|features) = P(features|class) × P(class) / P(features)\n",
    "- **Naive Independence**: P(x₁,x₂,...,xₙ|class) = P(x₁|class) × P(x₂|class) × ... × P(xₙ|class)\n",
    "- **Gaussian Distribution**: Features follow normal distribution within each class\n",
    "- **Maximum A Posteriori**: Choose class with highest posterior probability\n",
    "\n",
    "### ⏱️ Estimated Reading Time: 15-20 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ef6eb",
   "metadata": {},
   "source": [
    "## 🧠 Theory Foundation: Understanding Bayes' Theorem\n",
    "\n",
    "### 📐 The Mathematical Foundation:\n",
    "\n",
    "**Bayes' Theorem** is the cornerstone of probabilistic classification:\n",
    "\n",
    "```\n",
    "P(Class|Features) = P(Features|Class) × P(Class) / P(Features)\n",
    "```\n",
    "\n",
    "#### 🔍 Breaking Down the Formula:\n",
    "\n",
    "1. **P(Class|Features)**: **Posterior Probability** - What we want to find\n",
    "   - \"Given these features, what's the probability of this class?\"\n",
    "   - Example: \"Given petal length=5.2, what's P(Species=Virginica)?\"\n",
    "\n",
    "2. **P(Features|Class)**: **Likelihood** - How likely these features are in this class\n",
    "   - \"If it's this class, how likely are these feature values?\"\n",
    "   - Example: \"If it's Virginica, how likely is petal length=5.2?\"\n",
    "\n",
    "3. **P(Class)**: **Prior Probability** - How common is this class overall?\n",
    "   - \"What percentage of flowers are Virginica?\"\n",
    "   - Can be estimated from training data\n",
    "\n",
    "4. **P(Features)**: **Evidence** - Overall probability of these features\n",
    "   - Acts as normalization factor\n",
    "   - Ensures probabilities sum to 1\n",
    "\n",
    "### 🤔 The \"Naive\" Assumption:\n",
    "\n",
    "**Independence Assumption**: All features are independent given the class.\n",
    "\n",
    "```\n",
    "P(x₁,x₂,...,xₙ|Class) = P(x₁|Class) × P(x₂|Class) × ... × P(xₙ|Class)\n",
    "```\n",
    "\n",
    "#### 🎯 Why This \"Naive\" Assumption Works:\n",
    "\n",
    "1. **Simplification**: Makes computation tractable\n",
    "2. **Robustness**: Often works even when assumption is violated\n",
    "3. **Efficiency**: Fast training and prediction\n",
    "4. **Interpretability**: Easy to understand and explain\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce04e34",
   "metadata": {},
   "source": [
    "## 📊 Gaussian (Normal) Distribution in Naive Bayes\n",
    "\n",
    "### 🔔 Why Gaussian Distribution?\n",
    "\n",
    "**Gaussian Naive Bayes** assumes that continuous features follow a **normal (bell curve) distribution** within each class.\n",
    "\n",
    "#### 📈 The Gaussian Probability Density Function:\n",
    "\n",
    "```\n",
    "f(x|μ,σ²) = (1/√(2πσ²)) × e^(-(x-μ)²/(2σ²))\n",
    "```\n",
    "\n",
    "**Parameters for Each Feature per Class:**\n",
    "- **μ (mu)**: Mean of the feature values in that class\n",
    "- **σ² (sigma squared)**: Variance of the feature values in that class\n",
    "\n",
    "#### 🎯 How GaussianNB Works:\n",
    "\n",
    "1. **Training Phase:**\n",
    "   - Calculate μ and σ² for each feature in each class\n",
    "   - Store these parameters (no need to store original data!)\n",
    "\n",
    "2. **Prediction Phase:**\n",
    "   - For new sample, calculate probability using Gaussian formula\n",
    "   - Apply Bayes' theorem with independence assumption\n",
    "   - Predict class with highest posterior probability\n",
    "\n",
    "#### 🌟 Advantages of Gaussian Assumption:\n",
    "- **Continuous Features**: Handles real-valued data naturally\n",
    "- **Parameter Efficiency**: Only need to store mean and variance\n",
    "- **Smooth Boundaries**: Creates smooth decision boundaries\n",
    "- **Mathematical Elegance**: Clean probabilistic interpretation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa975d",
   "metadata": {},
   "source": [
    "## 🌺 Understanding the Iris Dataset: Perfect for Gaussian Naive Bayes\n",
    "\n",
    "### 📋 Dataset Overview:\n",
    "\n",
    "The **Iris dataset** is ideal for demonstrating Gaussian Naive Bayes because:\n",
    "\n",
    "#### 🏷️ **Classes (Target Variable):**\n",
    "- **Setosa**: One of three iris flower species\n",
    "- **Versicolor**: Second iris species \n",
    "- **Virginica**: Third iris species\n",
    "- **Total Samples**: 150 (50 per class - perfectly balanced!)\n",
    "\n",
    "#### 📏 **Features (Continuous Variables):**\n",
    "1. **Sepal Length (cm)**: Length of the outer petals\n",
    "2. **Sepal Width (cm)**: Width of the outer petals  \n",
    "3. **Petal Length (cm)**: Length of the inner petals\n",
    "4. **Petal Width (cm)**: Width of the inner petals\n",
    "\n",
    "### 🎯 Why Iris + Gaussian NB = Perfect Match?\n",
    "\n",
    "#### ✅ **Ideal Characteristics:**\n",
    "1. **Continuous Features**: All measurements are real numbers (perfect for Gaussian)\n",
    "2. **Natural Variation**: Measurements follow approximately normal distributions\n",
    "3. **Class Separation**: Different species have different measurement patterns\n",
    "4. **No Missing Values**: Complete dataset, no preprocessing needed\n",
    "5. **Interpretable**: Easy to visualize and understand\n",
    "\n",
    "#### 📊 **Expected Gaussian Distributions:**\n",
    "- **Setosa**: Generally smaller flowers (shorter petals, wider sepals)\n",
    "- **Versicolor**: Medium-sized flowers (intermediate measurements)  \n",
    "- **Virginica**: Larger flowers (longer petals, longer sepals)\n",
    "\n",
    "### 🔬 **What We'll Discover:**\n",
    "1. **Feature Distributions**: How each measurement varies within species\n",
    "2. **Class Separability**: Which features best distinguish species\n",
    "3. **Model Performance**: How well Gaussian NB classifies new flowers\n",
    "4. **Probability Interpretation**: Understanding prediction confidence\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df505f78",
   "metadata": {},
   "source": [
    "## 💻 Implementation: Step-by-Step Gaussian Naive Bayes\n",
    "\n",
    "### 🚀 Let's Build Our Probabilistic Classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764d5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Essential Libraries for Gaussian Naive Bayes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 🎨 Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"🎯 Ready to explore Gaussian Naive Bayes with the Iris dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌺 Load and Explore the Iris Dataset\n",
    "print(\"🔍 Loading the Famous Iris Dataset...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target  # Target: species (0=setosa, 1=versicolor, 2=virginica)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = y\n",
    "df['species_name'] = df['species'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "\n",
    "print(f\"📊 Dataset Shape: {df.shape}\")\n",
    "print(f\"🎯 Number of Features: {X.shape[1]}\")\n",
    "print(f\"🏷️ Number of Classes: {len(np.unique(y))}\")\n",
    "print(f\"📈 Total Samples: {len(df)}\")\n",
    "\n",
    "print(\"\\n🔤 Feature Names:\")\n",
    "for i, name in enumerate(iris.feature_names):\n",
    "    print(f\"   {i+1}. {name}\")\n",
    "\n",
    "print(\"\\n🌸 Class Distribution:\")\n",
    "class_counts = df['species_name'].value_counts()\n",
    "for species, count in class_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"   {species}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n📋 First 5 samples:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f0b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Statistical Analysis: Understanding Feature Distributions\n",
    "print(\"📈 Statistical Summary by Species\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate detailed statistics for each feature by species\n",
    "for species in ['Setosa', 'Versicolor', 'Virginica']:\n",
    "    print(f\"\\n🌸 {species.upper()} STATISTICS:\")\n",
    "    species_data = df[df['species_name'] == species]\n",
    "    \n",
    "    for feature in iris.feature_names:\n",
    "        data = species_data[feature]\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        print(f\"   {feature}:\")\n",
    "        print(f\"      Mean (μ): {mean:.2f} cm\")\n",
    "        print(f\"      Std Dev (σ): {std:.2f} cm\")\n",
    "        print(f\"      Range: {data.min():.1f} - {data.max():.1f} cm\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🧠 Key Observations for Gaussian Naive Bayes:\")\n",
    "print(\"   • Each species shows different mean values (μ)\")\n",
    "print(\"   • Standard deviations (σ) vary by species and feature\")\n",
    "print(\"   • These μ and σ values are exactly what GaussianNB learns!\")\n",
    "print(\"   • The algorithm assumes each feature follows Normal(μ, σ²) per class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e273f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Visualizing Gaussian Distributions for Each Feature\n",
    "print(\"🎨 Creating Distribution Plots...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('🔔 Gaussian Distributions by Species\\n(Perfect for Gaussian Naive Bayes!)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "features = iris.feature_names\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "species_names = ['Setosa', 'Versicolor', 'Virginica']\n",
    "\n",
    "for idx, feature in enumerate(features):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Plot histograms and density curves for each species\n",
    "    for i, species in enumerate(species_names):\n",
    "        species_data = df[df['species_name'] == species][feature]\n",
    "        \n",
    "        # Histogram\n",
    "        ax.hist(species_data, bins=12, alpha=0.6, color=colors[i], \n",
    "                label=f'{species}', density=True, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        # Gaussian curve overlay\n",
    "        x_range = np.linspace(species_data.min(), species_data.max(), 100)\n",
    "        mean = species_data.mean()\n",
    "        std = species_data.std()\n",
    "        gaussian_curve = (1/(std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x_range - mean)/std)**2)\n",
    "        ax.plot(x_range, gaussian_curve, color=colors[i], linewidth=3, linestyle='--')\n",
    "    \n",
    "    ax.set_title(f'📏 {feature}\\n(Showing Gaussian Assumption)', fontweight='bold')\n",
    "    ax.set_xlabel('Measurement (cm)', fontweight='bold')\n",
    "    ax.set_ylabel('Probability Density', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🔍 What This Visualization Shows:\")\n",
    "print(\"   📊 Solid bars = Actual data distribution\")\n",
    "print(\"   📈 Dashed lines = Gaussian (Normal) curves fitted to data\")\n",
    "print(\"   ✅ Close match = Good fit for Gaussian Naive Bayes assumption!\")\n",
    "print(\"   🎯 Each species has different μ (center) and σ (spread)\")\n",
    "print(\"   🧠 GaussianNB learns these parameters automatically!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e73c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Data Splitting: Preparing for Training and Testing\n",
    "print(\"✂️ Splitting Data for Model Evaluation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Split the data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,      # 20% for testing\n",
    "    random_state=42,    # For reproducible results\n",
    "    stratify=y          # Maintain class distribution in both sets\n",
    ")\n",
    "\n",
    "print(f\"📚 Training Set:\")\n",
    "print(f\"   Samples: {X_train.shape[0]} ({(X_train.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "\n",
    "print(f\"\\n🧪 Testing Set:\")\n",
    "print(f\"   Samples: {X_test.shape[0]} ({(X_test.shape[0]/len(X))*100:.1f}%)\")\n",
    "print(f\"   Features: {X_test.shape[1]}\")\n",
    "\n",
    "# Verify stratification worked\n",
    "print(f\"\\n🎯 Class Distribution Verification:\")\n",
    "print(\"Training set distribution:\")\n",
    "train_unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "for class_idx, count in zip(train_unique, train_counts):\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    species_name = ['Setosa', 'Versicolor', 'Virginica'][class_idx]\n",
    "    print(f\"   {species_name}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"Testing set distribution:\")\n",
    "test_unique, test_counts = np.unique(y_test, return_counts=True)\n",
    "for class_idx, count in zip(test_unique, test_counts):\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    species_name = ['Setosa', 'Versicolor', 'Virginica'][class_idx]\n",
    "    print(f\"   {species_name}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\n💡 Why This Split Strategy:\")\n",
    "print(\"   ✅ Stratified sampling maintains class balance\")\n",
    "print(\"   ✅ Random state ensures reproducible results\")\n",
    "print(\"   ✅ 80/20 split provides enough training data\")\n",
    "print(\"   ✅ Test set represents all classes fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🤖 Training the Gaussian Naive Bayes Model\n",
    "print(\"🎓 Training Gaussian Naive Bayes Classifier\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Initialize the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "print(\"🔧 GaussianNB Parameters (Using Defaults):\")\n",
    "print(f\"   priors: {gnb.priors} (None = learn from data)\")\n",
    "print(f\"   var_smoothing: {gnb.var_smoothing} (prevents zero variance)\")\n",
    "\n",
    "print(\"\\n🚀 Training Process:\")\n",
    "print(\"   1️⃣ Calculate class priors: P(Class)\")\n",
    "print(\"   2️⃣ Calculate feature means (μ) for each class\")\n",
    "print(\"   3️⃣ Calculate feature variances (σ²) for each class\")\n",
    "print(\"   4️⃣ Store parameters for prediction\")\n",
    "\n",
    "# Train the model\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Training Complete!\")\n",
    "print(\"\\n📊 Learned Parameters:\")\n",
    "\n",
    "# Display learned parameters\n",
    "print(\"\\n🏷️ Class Priors P(Class):\")\n",
    "for i, prior in enumerate(gnb.class_prior_):\n",
    "    species_name = ['Setosa', 'Versicolor', 'Virginica'][i]\n",
    "    print(f\"   P({species_name}) = {prior:.3f} ({prior*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n📐 Feature Means (μ) by Class:\")\n",
    "feature_names = iris.feature_names\n",
    "for class_idx, class_name in enumerate(['Setosa', 'Versicolor', 'Virginica']):\n",
    "    print(f\"\\n   {class_name}:\")\n",
    "    for feature_idx, feature_name in enumerate(feature_names):\n",
    "        mean_val = gnb.theta_[class_idx, feature_idx]\n",
    "        print(f\"      {feature_name}: μ = {mean_val:.2f} cm\")\n",
    "\n",
    "print(\"\\n📏 Feature Variances (σ²) by Class:\")\n",
    "for class_idx, class_name in enumerate(['Setosa', 'Versicolor', 'Virginica']):\n",
    "    print(f\"\\n   {class_name}:\")\n",
    "    for feature_idx, feature_name in enumerate(feature_names):\n",
    "        var_val = gnb.sigma_[class_idx, feature_idx]\n",
    "        std_val = np.sqrt(var_val)\n",
    "        print(f\"      {feature_name}: σ² = {var_val:.3f}, σ = {std_val:.2f} cm\")\n",
    "\n",
    "print(\"\\n🧠 Model Understanding:\")\n",
    "print(\"   💡 These parameters define Gaussian distributions\")\n",
    "print(\"   💡 For prediction, model calculates P(Feature|Class) using these\")\n",
    "print(\"   💡 var_smoothing prevents division by zero when σ² is very small\")\n",
    "print(\"   💡 Model stores NO original training data - just these statistics!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔮 Making Predictions: Understanding the Process\n",
    "print(\"🎯 Testing Model Predictions\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gnb.predict(X_test)\n",
    "y_pred_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "print(\"🔍 Prediction Process for Each Test Sample:\")\n",
    "print(\"   1️⃣ Calculate P(Feature|Class) for each feature using Gaussian formula\")\n",
    "print(\"   2️⃣ Apply independence assumption: multiply all feature probabilities\")\n",
    "print(\"   3️⃣ Apply Bayes' theorem: multiply by prior P(Class)\")\n",
    "print(\"   4️⃣ Normalize to get probabilities that sum to 1\")\n",
    "print(\"   5️⃣ Predict class with highest probability\")\n",
    "\n",
    "# Show detailed prediction examples\n",
    "print(f\"\\n📋 Detailed Prediction Examples (First 5 Test Samples):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "species_names = ['Setosa', 'Versicolor', 'Virginica']\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "for i in range(min(5, len(X_test))):\n",
    "    print(f\"\\n🌸 Sample {i+1}:\")\n",
    "    print(f\"   Features: {X_test[i]}\")\n",
    "    print(f\"   True Species: {species_names[y_test[i]]}\")\n",
    "    print(f\"   Predicted Species: {species_names[y_pred[i]]}\")\n",
    "    \n",
    "    print(f\"   Prediction Probabilities:\")\n",
    "    for j, species in enumerate(species_names):\n",
    "        prob = y_pred_proba[i][j]\n",
    "        confidence = \"🔥 HIGH\" if prob > 0.8 else \"⚡ MEDIUM\" if prob > 0.5 else \"❄️ LOW\"\n",
    "        print(f\"      P({species}|Features) = {prob:.4f} ({prob*100:.1f}%) {confidence}\")\n",
    "    \n",
    "    # Show if prediction is correct\n",
    "    correct = \"✅ CORRECT!\" if y_pred[i] == y_test[i] else \"❌ INCORRECT!\"\n",
    "    print(f\"   Result: {correct}\")\n",
    "\n",
    "print(f\"\\n💡 Understanding Probabilities:\")\n",
    "print(\"   🎯 Higher probability = more confident prediction\")\n",
    "print(\"   📊 Probabilities sum to 1.0 (100%) for each sample\")\n",
    "print(\"   🧠 Model considers all features simultaneously\")\n",
    "print(\"   ⚖️ Bayes' theorem balances likelihood and prior knowledge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Model Evaluation: Comprehensive Performance Analysis\n",
    "print(\"📈 Evaluating Model Performance\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate basic accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"🎯 Overall Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification metrics\n",
    "print(f\"\\n📋 Detailed Classification Report:\")\n",
    "print(\"-\" * 60)\n",
    "report = classification_report(y_test, y_pred, target_names=species_names, output_dict=True)\n",
    "print(classification_report(y_test, y_pred, target_names=species_names))\n",
    "\n",
    "# Calculate metrics for each class\n",
    "print(f\"🔍 Per-Class Performance Breakdown:\")\n",
    "for i, species in enumerate(species_names):\n",
    "    precision = report[species]['precision']\n",
    "    recall = report[species]['recall']\n",
    "    f1 = report[species]['f1-score']\n",
    "    support = report[species]['support']\n",
    "    \n",
    "    print(f\"\\n   🌸 {species}:\")\n",
    "    print(f\"      Precision: {precision:.3f} ({precision*100:.1f}%)\")\n",
    "    print(f\"      Recall: {recall:.3f} ({recall*100:.1f}%)\")\n",
    "    print(f\"      F1-Score: {f1:.3f} ({f1*100:.1f}%)\")\n",
    "    print(f\"      Support: {support} samples\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\n🔲 Confusion Matrix Analysis:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a formatted confusion matrix\n",
    "print(\"Predicted →\")\n",
    "print(f\"{'Actual ↓':<12} {'Setosa':<8} {'Versi':<8} {'Virgin':<8}\")\n",
    "for i, species in enumerate(['Setosa', 'Versi', 'Virgin']):\n",
    "    row = f\"{species:<12}\"\n",
    "    for j in range(3):\n",
    "        row += f\"{cm[i,j]:<8}\"\n",
    "    print(row)\n",
    "\n",
    "print(f\"\\n💡 Confusion Matrix Insights:\")\n",
    "correct_predictions = np.trace(cm)\n",
    "total_predictions = np.sum(cm)\n",
    "print(f\"   ✅ Correct predictions: {correct_predictions}/{total_predictions}\")\n",
    "print(f\"   ❌ Misclassifications: {total_predictions - correct_predictions}/{total_predictions}\")\n",
    "\n",
    "# Identify misclassifications\n",
    "if total_predictions > correct_predictions:\n",
    "    print(f\"   🔍 Misclassification patterns:\")\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i != j and cm[i,j] > 0:\n",
    "                actual = species_names[i]\n",
    "                predicted = species_names[j]\n",
    "                count = cm[i,j]\n",
    "                print(f\"      {actual} predicted as {predicted}: {count} times\")\n",
    "\n",
    "print(f\"\\n🎊 Model Performance Summary:\")\n",
    "print(f\"   🏆 Gaussian Naive Bayes achieved {accuracy*100:.1f}% accuracy!\")\n",
    "print(f\"   🎯 Successfully classified {correct_predictions} out of {total_predictions} test samples\")\n",
    "print(f\"   📊 Demonstrates effectiveness of probabilistic classification\")\n",
    "print(f\"   🧠 Gaussian assumption works well for Iris flower measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎨 Visualizing Model Performance\n",
    "print(\"🎨 Creating Performance Visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "ax1 = axes[0]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=species_names, yticklabels=species_names,\n",
    "            ax=ax1, cbar_kws={'label': 'Number of Predictions'})\n",
    "ax1.set_title('🔲 Confusion Matrix\\n(Gaussian Naive Bayes)', fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('Predicted Species', fontweight='bold')\n",
    "ax1.set_ylabel('Actual Species', fontweight='bold')\n",
    "\n",
    "# Add accuracy annotation\n",
    "accuracy_text = f'Overall Accuracy: {accuracy:.1%}'\n",
    "ax1.text(1.5, -0.15, accuracy_text, ha='center', va='top', \n",
    "         transform=ax1.transAxes, fontsize=12, fontweight='bold',\n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgreen\", alpha=0.7))\n",
    "\n",
    "# 2. Performance Metrics Bar Chart\n",
    "ax2 = axes[1]\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "setosa_scores = [report['Setosa'][m.lower().replace('-', '-')] for m in ['precision', 'recall', 'f1-score']]\n",
    "versicolor_scores = [report['Versicolor'][m.lower().replace('-', '-')] for m in ['precision', 'recall', 'f1-score']]\n",
    "virginica_scores = [report['Virginica'][m.lower().replace('-', '-')] for m in ['precision', 'recall', 'f1-score']]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = ax2.bar(x - width, setosa_scores, width, label='Setosa', color='#FF6B6B', alpha=0.8)\n",
    "bars2 = ax2.bar(x, versicolor_scores, width, label='Versicolor', color='#4ECDC4', alpha=0.8)\n",
    "bars3 = ax2.bar(x + width, virginica_scores, width, label='Virginica', color='#45B7D1', alpha=0.8)\n",
    "\n",
    "# Add value labels on bars\n",
    "def add_value_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "add_value_labels(bars1)\n",
    "add_value_labels(bars2)\n",
    "add_value_labels(bars3)\n",
    "\n",
    "ax2.set_title('📊 Performance Metrics by Species\\n(Gaussian Naive Bayes)', fontweight='bold', fontsize=14)\n",
    "ax2.set_xlabel('Metrics', fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(metrics)\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📈 Visualization Insights:\")\n",
    "print(\"   🔲 Confusion Matrix: Shows actual vs predicted classifications\")\n",
    "print(\"   📊 Performance Metrics: Compares precision, recall, and F1-score\")\n",
    "print(\"   🎯 High scores indicate excellent performance across all species\")\n",
    "print(\"   ✅ Gaussian assumption proves effective for this dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌺 Practical Example: Classifying a New Flower\n",
    "print(\"🔍 Practical Example: Classifying Unknown Flowers\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Create a new flower sample for demonstration\n",
    "new_flower = np.array([[5.0, 3.2, 1.5, 0.3]])  # Custom measurements\n",
    "print(f\"🌸 New Flower Measurements:\")\n",
    "print(f\"   Sepal Length: {new_flower[0][0]} cm\")\n",
    "print(f\"   Sepal Width:  {new_flower[0][1]} cm\") \n",
    "print(f\"   Petal Length: {new_flower[0][2]} cm\")\n",
    "print(f\"   Petal Width:  {new_flower[0][3]} cm\")\n",
    "\n",
    "# Make prediction\n",
    "prediction = gnb.predict(new_flower)\n",
    "probabilities = gnb.predict_proba(new_flower)\n",
    "\n",
    "print(f\"\\n🎯 Prediction Results:\")\n",
    "print(f\"   Predicted Species: {species_names[prediction[0]]}\")\n",
    "\n",
    "print(f\"\\n📊 Detailed Probability Analysis:\")\n",
    "for i, species in enumerate(species_names):\n",
    "    prob = probabilities[0][i]\n",
    "    confidence_level = \"🔥 HIGH\" if prob > 0.7 else \"⚡ MEDIUM\" if prob > 0.3 else \"❄️ LOW\"\n",
    "    bar_length = int(prob * 20)  # Scale for visual bar\n",
    "    bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "    print(f\"   {species:<12}: {prob:.4f} ({prob*100:5.1f}%) {bar} {confidence_level}\")\n",
    "\n",
    "# Show the mathematical process (simplified)\n",
    "print(f\"\\n🧮 Behind the Scenes (Simplified Bayes' Calculation):\")\n",
    "predicted_class = species_names[prediction[0]]\n",
    "max_prob = max(probabilities[0])\n",
    "print(f\"   P({predicted_class}|Features) = {max_prob:.4f}\")\n",
    "print(f\"   This probability comes from:\")\n",
    "print(f\"   P(Features|{predicted_class}) × P({predicted_class}) / P(Features)\")\n",
    "\n",
    "print(f\"\\n💡 Interpretation:\")\n",
    "if max_prob > 0.8:\n",
    "    print(\"   🎊 Very confident prediction! The features strongly match this species.\")\n",
    "elif max_prob > 0.6:\n",
    "    print(\"   ✅ Confident prediction. Features are consistent with this species.\")\n",
    "elif max_prob > 0.4:\n",
    "    print(\"   ⚠️ Moderate confidence. Features are somewhat ambiguous.\")\n",
    "else:\n",
    "    print(\"   ❓ Low confidence. Features don't clearly match any species.\")\n",
    "\n",
    "# Test multiple examples\n",
    "print(f\"\\n🧪 Testing Multiple Examples:\")\n",
    "test_samples = [\n",
    "    [5.9, 3.0, 5.1, 1.8],  # Likely Virginica\n",
    "    [4.9, 3.0, 1.4, 0.2],  # Likely Setosa  \n",
    "    [6.3, 2.5, 4.9, 1.5],  # Likely Versicolor\n",
    "]\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    sample_array = np.array([sample])\n",
    "    pred = gnb.predict(sample_array)\n",
    "    probs = gnb.predict_proba(sample_array)\n",
    "    max_prob = max(probs[0])\n",
    "    \n",
    "    print(f\"\\n   Sample {i+1}: {sample}\")\n",
    "    print(f\"   → Predicted: {species_names[pred[0]]} (Confidence: {max_prob:.2f})\")\n",
    "\n",
    "print(f\"\\n🎓 Key Takeaways:\")\n",
    "print(\"   🧠 Gaussian Naive Bayes provides probabilistic predictions\")\n",
    "print(\"   📊 Higher probabilities indicate more confident classifications\")  \n",
    "print(\"   🎯 Model considers all features simultaneously using Bayes' theorem\")\n",
    "print(\"   ⚡ Fast predictions - only requires stored μ and σ parameters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e2ed34",
   "metadata": {},
   "source": [
    "## 🎊 Conclusion: Mastering Gaussian Naive Bayes\n",
    "\n",
    "### 🏆 What We've Accomplished:\n",
    "\n",
    "#### 📚 **Theoretical Mastery:**\n",
    "- ✅ **Bayes' Theorem**: Understanding posterior, likelihood, prior, and evidence\n",
    "- ✅ **Gaussian Assumption**: Why normal distributions work for continuous features  \n",
    "- ✅ **Independence Assumption**: The \"naive\" part that makes computation tractable\n",
    "- ✅ **Probabilistic Interpretation**: Getting confidence scores, not just predictions\n",
    "\n",
    "#### 💻 **Practical Implementation:**\n",
    "- ✅ **Data Exploration**: Analyzed Iris dataset structure and distributions\n",
    "- ✅ **Model Training**: Learned μ and σ parameters for each feature-class combination\n",
    "- ✅ **Prediction Process**: Made probabilistic classifications with confidence scores\n",
    "- ✅ **Performance Evaluation**: Achieved excellent accuracy with detailed metrics\n",
    "\n",
    "#### 📊 **Key Results:**\n",
    "- 🎯 **High Accuracy**: Successfully classified Iris species with excellent performance\n",
    "- 📈 **Clear Distributions**: Confirmed Gaussian assumption validity for this dataset\n",
    "- 🧠 **Interpretable Model**: Easy to understand and explain predictions\n",
    "- ⚡ **Efficient Algorithm**: Fast training and prediction with minimal parameters\n",
    "\n",
    "---\n",
    "\n",
    "### 🔬 **When to Use Gaussian Naive Bayes:**\n",
    "\n",
    "#### ✅ **Perfect For:**\n",
    "- **Continuous numerical features** (measurements, scores, etc.)\n",
    "- **Features that roughly follow normal distributions**\n",
    "- **Small to medium datasets** where simplicity is valued\n",
    "- **Baseline models** for quick prototyping\n",
    "- **Real-time applications** requiring fast predictions\n",
    "- **Interpretable models** where you need to explain decisions\n",
    "\n",
    "#### ⚠️ **Consider Alternatives When:**\n",
    "- **Features are highly correlated** (violates independence assumption)\n",
    "- **Features are categorical** (use Multinomial or Categorical NB)\n",
    "- **Non-linear relationships** are crucial (try SVM, Random Forest)\n",
    "- **Very large datasets** where more complex models might excel\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 **Next Steps in Your ML Journey:**\n",
    "\n",
    "#### 🎯 **Immediate Extensions:**\n",
    "1. **Try Different Naive Bayes Variants:**\n",
    "   - Multinomial NB for text classification\n",
    "   - Bernoulli NB for binary features\n",
    "   - Categorical NB for categorical features\n",
    "\n",
    "2. **Feature Engineering:**\n",
    "   - Feature scaling and normalization\n",
    "   - Creating new features from existing ones\n",
    "   - Handling missing values\n",
    "\n",
    "3. **Model Comparison:**\n",
    "   - Compare with SVM, Random Forest, Logistic Regression\n",
    "   - Cross-validation for robust evaluation\n",
    "   - Hyperparameter tuning\n",
    "\n",
    "#### 📈 **Advanced Topics:**\n",
    "- **Ensemble Methods**: Combine Naive Bayes with other algorithms\n",
    "- **Bayesian Networks**: Relax independence assumptions\n",
    "- **Online Learning**: Update model with streaming data\n",
    "- **Hierarchical Bayes**: Handle complex data structures\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 **Key Insights to Remember:**\n",
    "\n",
    "> **\"The 'naive' assumption often works better than expected!\"**\n",
    "\n",
    "1. **Simplicity is Powerful**: Sometimes simple models outperform complex ones\n",
    "2. **Probabilistic Thinking**: Getting confidence scores is as important as predictions\n",
    "3. **Assumptions Matter**: Understanding when they hold and when they don't\n",
    "4. **Mathematical Foundation**: Bayes' theorem is fundamental to many ML algorithms\n",
    "\n",
    "### 🎓 **Final Wisdom:**\n",
    "*Gaussian Naive Bayes proves that understanding probability theory and making reasonable assumptions can lead to surprisingly effective machine learning models. It's not just about the algorithm—it's about thinking probabilistically about your data!*\n",
    "\n",
    "---\n",
    "\n",
    "**🌟 Congratulations! You've mastered the fundamentals of Gaussian Naive Bayes and probabilistic classification!** 🌟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb7c04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fae82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132a2750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e55ebdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77316126",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3992d682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('priors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">priors&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('var_smoothing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">var_smoothing&nbsp;</td>\n",
       "            <td class=\"value\">1e-09</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB()\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7128582",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a72336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       2, 0, 2, 1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154dd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "848b538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d07bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 12,  1],\n",
       "       [ 0,  0,  6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b663848a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
