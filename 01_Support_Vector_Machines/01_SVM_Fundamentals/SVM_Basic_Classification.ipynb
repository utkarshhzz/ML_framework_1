{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "335e711c",
   "metadata": {},
   "source": [
    "# üéØ SVM Basic Classification - Complete Learning Guide\n",
    "*From Zero to SVM Mastery with Detailed Explanations*\n",
    "\n",
    "## üéì Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will understand:\n",
    "- ‚úÖ **What SVM is and why it's powerful** - Mathematical intuition behind maximum margin\n",
    "- ‚úÖ **How SVM finds decision boundaries** - The optimization problem SVM solves\n",
    "- ‚úÖ **When to use SVM vs other algorithms** - Practical decision-making guide\n",
    "- ‚úÖ **SVM parameters and their effects** - C, gamma, and kernel selection\n",
    "- ‚úÖ **Complete model evaluation process** - From training to performance analysis\n",
    "- ‚úÖ **Hyperparameter tuning with GridSearch** - Finding optimal settings systematically\n",
    "\n",
    "## üß† SVM Intuition - The \"Maximum Margin\" Concept\n",
    "\n",
    "**Think of SVM like this:** Imagine you're separating two groups of people in a room with a rope. You could put the rope anywhere that separates them, but SVM puts it in the spot that's **as far as possible from both groups**. This creates the biggest \"safety zone\" on both sides.\n",
    "\n",
    "### üìä Why Maximum Margin Matters:\n",
    "- **Better generalization**: Wide margins mean the model is more confident about its decisions\n",
    "- **Robust to new data**: New points are less likely to fall in the \"uncertain\" area\n",
    "- **Mathematical elegance**: The optimization problem has a unique, global solution\n",
    "\n",
    "### üéØ SVM vs Other Algorithms:\n",
    "\n",
    "| **Algorithm** | **Decision Strategy** | **When to Use** |\n",
    "|---------------|----------------------|-----------------|\n",
    "| **SVM** | Maximize margin between classes | Small-medium datasets, high dimensions, need robust boundaries |\n",
    "| **Decision Tree** | Find simple yes/no questions | Need interpretability, mixed data types |\n",
    "| **Logistic Regression** | Find linear probability boundary | Need probability estimates, simple interpretation |\n",
    "| **Neural Network** | Learn complex non-linear patterns | Large datasets, complex patterns, have computational resources |\n",
    "\n",
    "## üõ†Ô∏è What We'll Build Today\n",
    "\n",
    "We'll create a complete SVM classification system that:\n",
    "1. **Generates synthetic data** with controlled complexity\n",
    "2. **Visualizes decision boundaries** to understand how SVM works\n",
    "3. **Compares different SVM configurations** (linear vs RBF kernels)\n",
    "4. **Performs hyperparameter tuning** to find optimal settings\n",
    "5. **Evaluates performance** with comprehensive metrics\n",
    "6. **Provides practical insights** for real-world usage\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Code Structure Overview\n",
    "\n",
    "This notebook follows a systematic approach:\n",
    "- **Data Generation**: Create controlled synthetic datasets\n",
    "- **Exploratory Analysis**: Understand our data characteristics\n",
    "- **Model Training**: Train SVM with different configurations\n",
    "- **Visualization**: Plot decision boundaries and support vectors\n",
    "- **Hyperparameter Tuning**: Optimize model performance\n",
    "- **Evaluation**: Comprehensive performance analysis\n",
    "- **Practical Insights**: When and how to use SVM in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ IMPORTS AND SETUP\n",
    "# ======================\n",
    "\n",
    "# Core data manipulation and analysis\n",
    "import pandas as pd          # Data manipulation and analysis library\n",
    "import numpy as np          # Numerical computing library\n",
    "\n",
    "# Visualization libraries\n",
    "import seaborn as sns       # Statistical data visualization (built on matplotlib)\n",
    "import matplotlib.pyplot as plt  # Basic plotting library\n",
    "\n",
    "# Configuration for better plots\n",
    "plt.style.use('seaborn-v0_8')  # Use seaborn's clean styling\n",
    "sns.set_palette(\"husl\")         # Use visually appealing color palette\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"üìä Plot styling configured for better visualizations\")\n",
    "print(\"üîß Warnings suppressed for cleaner output\")\n",
    "\n",
    "# Let's verify our setup with a quick test\n",
    "print(f\"\\nüìã Environment Information:\")\n",
    "print(f\"   NumPy version: {np.__version__}\")\n",
    "print(f\"   Pandas version: {pd.__version__}\")\n",
    "print(f\"   Matplotlib backend: {plt.get_backend()}\")\n",
    "\n",
    "# Set global random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print(f\"üé≤ Random seed set to 42 for reproducible results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f58f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé≤ SYNTHETIC DATA GENERATION\n",
    "# =============================\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic dataset with controlled properties\n",
    "# This gives us complete control over the data characteristics\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,           # Total number of data points to generate\n",
    "    n_features=2,             # Number of features (we use 2 for easy visualization)\n",
    "    n_classes=2,              # Number of classes (binary classification)\n",
    "    n_clusters_per_class=2,   # Each class has 2 clusters (makes problem more interesting)\n",
    "    n_redundant=0,            # No redundant features (all features are useful)\n",
    "    n_informative=2,          # All features are informative\n",
    "    class_sep=1.0,            # Difficulty level (1.0 = moderate separation)\n",
    "    random_state=42           # For reproducible results\n",
    ")\n",
    "\n",
    "print(\"üéØ Synthetic Dataset Generated Successfully!\")\n",
    "print(f\"üìä Dataset Shape: {X.shape} (samples √ó features)\")\n",
    "print(f\"üè∑Ô∏è Target Shape: {y.shape}\")\n",
    "print(f\"üìà Feature names: ['Feature_1', 'Feature_2'] (synthetic)\")\n",
    "print(f\"üé≠ Classes: {np.unique(y)} (0 and 1)\")\n",
    "\n",
    "# Check class distribution\n",
    "unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "print(f\"\\nüìä Class Distribution:\")\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    percentage = (count / len(y)) * 100\n",
    "    print(f\"   Class {cls}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Basic statistics about features\n",
    "print(f\"\\nüìà Feature Statistics:\")\n",
    "for i in range(X.shape[1]):\n",
    "    print(f\"   Feature {i+1}: min={X[:, i].min():.2f}, max={X[:, i].max():.2f}, \"\n",
    "          f\"mean={X[:, i].mean():.2f}, std={X[:, i].std():.2f}\")\n",
    "\n",
    "print(f\"\\nüí° Why these parameters?\")\n",
    "print(f\"   ‚Ä¢ n_samples=1000: Large enough for stable results, small enough for fast computation\")\n",
    "print(f\"   ‚Ä¢ n_features=2: Allows us to visualize decision boundaries in 2D\")\n",
    "print(f\"   ‚Ä¢ n_clusters_per_class=2: Creates more realistic, complex class distributions\")\n",
    "print(f\"   ‚Ä¢ class_sep=1.0: Moderate difficulty - not too easy, not too hard\")\n",
    "print(f\"   ‚Ä¢ random_state=42: Ensures we get the same data every time we run this\")\n",
    "\n",
    "# WHAT THIS DATA REPRESENTS:\n",
    "# Think of this as measurements of two properties of some objects (like height and weight)\n",
    "# where we want to classify objects into two categories (like 'Type A' and 'Type B')\n",
    "# The clusters represent natural groupings within each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb4d378",
   "metadata": {},
   "source": [
    "# üìä DATA VISUALIZATION AND EXPLORATION\n",
    "# =====================================\n",
    "\n",
    "# Let's visualize our synthetic dataset to understand what we're working with\n",
    "\n",
    "# Create a comprehensive plot showing our data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Basic scatter plot colored by class\n",
    "axes[0].scatter(X[y == 0, 0], X[y == 0, 1], c='red', alpha=0.6, s=50, label='Class 0', edgecolors='black')\n",
    "axes[0].scatter(X[y == 1, 0], X[y == 1, 1], c='blue', alpha=0.6, s=50, label='Class 1', edgecolors='black')\n",
    "axes[0].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[0].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[0].set_title('Synthetic Dataset - Two Classes\\n(This is what SVM needs to separate)', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations to explain what we see\n",
    "axes[0].annotate('Class 0 clusters\\n(Red points)', xy=(np.mean(X[y == 0, 0]), np.mean(X[y == 0, 1])), \n",
    "                xytext=(10, 10), textcoords='offset points', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "axes[0].annotate('Class 1 clusters\\n(Blue points)', xy=(np.mean(X[y == 1, 0]), np.mean(X[y == 1, 1])), \n",
    "                xytext=(-60, -30), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='blue', alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "# Plot 2: Feature distribution histograms\n",
    "axes[1].hist(X[y == 0, 0], alpha=0.5, color='red', label='Class 0 - Feature 1', bins=30)\n",
    "axes[1].hist(X[y == 1, 0], alpha=0.5, color='blue', label='Class 1 - Feature 1', bins=30)\n",
    "axes[1].hist(X[y == 0, 1], alpha=0.5, color='pink', label='Class 0 - Feature 2', bins=30)\n",
    "axes[1].hist(X[y == 1, 1], alpha=0.5, color='lightblue', label='Class 1 - Feature 2', bins=30)\n",
    "axes[1].set_xlabel('Feature Values', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Feature Distributions by Class\\n(Shows overlap and separability)', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç What we can observe from the plots:\")\n",
    "print(\"   üìä Left plot: Shows the 2D scatter of our data points\")\n",
    "print(\"      ‚Ä¢ Red points = Class 0, Blue points = Class 1\")\n",
    "print(\"      ‚Ä¢ Each class has multiple clusters (not just one blob)\")\n",
    "print(\"      ‚Ä¢ Classes are separable but not with a simple linear boundary\")\n",
    "print(\"\")\n",
    "print(\"   üìà Right plot: Shows distribution of feature values\")\n",
    "print(\"      ‚Ä¢ Overlapping distributions indicate classification challenge\")\n",
    "print(\"      ‚Ä¢ Both features contribute to class separation\")\n",
    "print(\"      ‚Ä¢ No single feature perfectly separates the classes\")\n",
    "\n",
    "# Additional analysis: separability assessment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate average distance between classes\n",
    "class_0_center = np.mean(X[y == 0], axis=0)\n",
    "class_1_center = np.mean(X[y == 1], axis=0)\n",
    "inter_class_distance = np.linalg.norm(class_0_center - class_1_center)\n",
    "\n",
    "# Calculate average intra-class distances\n",
    "intra_class_0 = np.mean(cdist(X[y == 0], [class_0_center]))\n",
    "intra_class_1 = np.mean(cdist(X[y == 1], [class_1_center]))\n",
    "avg_intra_class = (intra_class_0 + intra_class_1) / 2\n",
    "\n",
    "separability_ratio = inter_class_distance / avg_intra_class\n",
    "\n",
    "print(f\"\\nüìè Separability Analysis:\")\n",
    "print(f\"   Inter-class distance: {inter_class_distance:.2f}\")\n",
    "print(f\"   Average intra-class distance: {avg_intra_class:.2f}\")\n",
    "print(f\"   Separability ratio: {separability_ratio:.2f}\")\n",
    "print(f\"   {'‚úÖ Well-separated classes' if separability_ratio > 2 else '‚ö†Ô∏è Challenging separation'}\")\n",
    "\n",
    "print(f\"\\nüéØ This dataset is perfect for learning SVM because:\")\n",
    "print(f\"   ‚Ä¢ It's 2D so we can visualize decision boundaries\")\n",
    "print(f\"   ‚Ä¢ It has moderate complexity (not too easy, not too hard)\")\n",
    "print(f\"   ‚Ä¢ Both linear and non-linear approaches will be needed\")\n",
    "print(f\"   ‚Ä¢ We can see the 'maximum margin' concept in action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f40a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12740197, -1.16560709],\n",
       "       [-0.71468574,  0.89089699],\n",
       "       [ 0.26690584, -1.31299478],\n",
       "       ...,\n",
       "       [ 0.27445215, -1.11710978],\n",
       "       [-0.69526785,  1.03960581],\n",
       "       [-0.12578708, -0.84654172]], shape=(1000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üìä DATA VISUALIZATION AND EXPLORATION\n",
    "# =====================================\n",
    "\n",
    "# Let's visualize our synthetic dataset to understand what we're working with\n",
    "\n",
    "# Create a comprehensive plot showing our data\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Basic scatter plot colored by class\n",
    "axes[0].scatter(X[y == 0, 0], X[y == 0, 1], c='red', alpha=0.6, s=50, label='Class 0', edgecolors='black')\n",
    "axes[0].scatter(X[y == 1, 0], X[y == 1, 1], c='blue', alpha=0.6, s=50, label='Class 1', edgecolors='black')\n",
    "axes[0].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[0].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[0].set_title('Synthetic Dataset - Two Classes\\n(This is what SVM needs to separate)', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations to explain what we see\n",
    "axes[0].annotate('Class 0 clusters\\n(Red points)', xy=(np.mean(X[y == 0, 0]), np.mean(X[y == 0, 1])), \n",
    "                xytext=(10, 10), textcoords='offset points', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='red', alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', color='red'))\n",
    "\n",
    "axes[0].annotate('Class 1 clusters\\n(Blue points)', xy=(np.mean(X[y == 1, 0]), np.mean(X[y == 1, 1])), \n",
    "                xytext=(-60, -30), textcoords='offset points',\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='blue', alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', color='blue'))\n",
    "\n",
    "# Plot 2: Feature distribution histograms\n",
    "axes[1].hist(X[y == 0, 0], alpha=0.5, color='red', label='Class 0 - Feature 1', bins=30)\n",
    "axes[1].hist(X[y == 1, 0], alpha=0.5, color='blue', label='Class 1 - Feature 1', bins=30)\n",
    "axes[1].hist(X[y == 0, 1], alpha=0.5, color='pink', label='Class 0 - Feature 2', bins=30)\n",
    "axes[1].hist(X[y == 1, 1], alpha=0.5, color='lightblue', label='Class 1 - Feature 2', bins=30)\n",
    "axes[1].set_xlabel('Feature Values', fontsize=12)\n",
    "axes[1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1].set_title('Feature Distributions by Class\\n(Shows overlap and separability)', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç What we can observe from the plots:\")\n",
    "print(\"   üìä Left plot: Shows the 2D scatter of our data points\")\n",
    "print(\"      ‚Ä¢ Red points = Class 0, Blue points = Class 1\")\n",
    "print(\"      ‚Ä¢ Each class has multiple clusters (not just one blob)\")\n",
    "print(\"      ‚Ä¢ Classes are separable but not with a simple linear boundary\")\n",
    "print(\"\")\n",
    "print(\"   üìà Right plot: Shows distribution of feature values\")\n",
    "print(\"      ‚Ä¢ Overlapping distributions indicate classification challenge\")\n",
    "print(\"      ‚Ä¢ Both features contribute to class separation\")\n",
    "print(\"      ‚Ä¢ No single feature perfectly separates the classes\")\n",
    "\n",
    "# Additional analysis: separability assessment\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate average distance between classes\n",
    "class_0_center = np.mean(X[y == 0], axis=0)\n",
    "class_1_center = np.mean(X[y == 1], axis=0)\n",
    "inter_class_distance = np.linalg.norm(class_0_center - class_1_center)\n",
    "\n",
    "# Calculate average intra-class distances\n",
    "intra_class_0 = np.mean(cdist(X[y == 0], [class_0_center]))\n",
    "intra_class_1 = np.mean(cdist(X[y == 1], [class_1_center]))\n",
    "avg_intra_class = (intra_class_0 + intra_class_1) / 2\n",
    "\n",
    "separability_ratio = inter_class_distance / avg_intra_class\n",
    "\n",
    "print(f\"\\nüìè Separability Analysis:\")\n",
    "print(f\"   Inter-class distance: {inter_class_distance:.2f}\")\n",
    "print(f\"   Average intra-class distance: {avg_intra_class:.2f}\")\n",
    "print(f\"   Separability ratio: {separability_ratio:.2f}\")\n",
    "print(f\"   {'‚úÖ Well-separated classes' if separability_ratio > 2 else '‚ö†Ô∏è Challenging separation'}\")\n",
    "\n",
    "print(f\"\\nüéØ This dataset is perfect for learning SVM because:\")\n",
    "print(f\"   ‚Ä¢ It's 2D so we can visualize decision boundaries\")\n",
    "print(f\"   ‚Ä¢ It has moderate complexity (not too easy, not too hard)\")\n",
    "print(f\"   ‚Ä¢ Both linear and non-linear approaches will be needed\")\n",
    "print(f\"   ‚Ä¢ We can see the 'maximum margin' concept in action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚úÇÔ∏è DATA SPLITTING: PREPARING FOR MACHINE LEARNING\n",
    "# ================================================\n",
    "\n",
    "# Before training any model, we need to split our data into training and testing sets\n",
    "# This is fundamental to machine learning - we train on one set and test on another\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,                    # Our features and labels\n",
    "    test_size=0.3,          # 30% for testing, 70% for training\n",
    "    random_state=42,        # For reproducible results\n",
    "    stratify=y              # Maintain class proportions in both sets\n",
    ")\n",
    "\n",
    "print(\"üìä DATA SPLITTING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Original dataset size: {X.shape[0]} samples\")\n",
    "print(f\"Training set size:     {X_train.shape[0]} samples ({(X_train.shape[0]/X.shape[0]*100):.1f}%)\")\n",
    "print(f\"Testing set size:      {X_test.shape[0]} samples ({(X_test.shape[0]/X.shape[0]*100):.1f}%)\")\n",
    "\n",
    "# Check class distribution in both sets\n",
    "from collections import Counter\n",
    "\n",
    "train_class_distribution = Counter(y_train)\n",
    "test_class_distribution = Counter(y_test)\n",
    "\n",
    "print(f\"\\nüéØ CLASS DISTRIBUTION ANALYSIS:\")\n",
    "print(f\"Training set - Class 0: {train_class_distribution[0]}, Class 1: {train_class_distribution[1]}\")\n",
    "print(f\"Testing set  - Class 0: {test_class_distribution[0]}, Class 1: {test_class_distribution[1]}\")\n",
    "\n",
    "# Calculate class proportions\n",
    "train_ratio = train_class_distribution[1] / (train_class_distribution[0] + train_class_distribution[1])\n",
    "test_ratio = test_class_distribution[1] / (test_class_distribution[0] + test_class_distribution[1])\n",
    "\n",
    "print(f\"\\nClass 1 proportion in training: {train_ratio:.3f}\")\n",
    "print(f\"Class 1 proportion in testing:  {test_ratio:.3f}\")\n",
    "print(f\"Difference: {abs(train_ratio - test_ratio):.3f} ({'‚úÖ Good' if abs(train_ratio - test_ratio) < 0.05 else '‚ö†Ô∏è Check'})\")\n",
    "\n",
    "print(f\"\\nüß† WHY WE SPLIT THE DATA:\")\n",
    "print(f\"   üéì Training Set (70%): Used to teach the SVM algorithm\")\n",
    "print(f\"      ‚Ä¢ The algorithm learns patterns from this data\")\n",
    "print(f\"      ‚Ä¢ It finds the optimal decision boundary here\")\n",
    "print(f\"      ‚Ä¢ Think of this as 'study material' for the algorithm\")\n",
    "print(f\"\")\n",
    "print(f\"   üß™ Testing Set (30%): Used to evaluate how well SVM learned\")\n",
    "print(f\"      ‚Ä¢ The algorithm has NEVER seen this data during training\")\n",
    "print(f\"      ‚Ä¢ We use it to check if the model generalizes well\")\n",
    "print(f\"      ‚Ä¢ Think of this as the 'final exam' for the algorithm\")\n",
    "print(f\"\")\n",
    "print(f\"   üîÑ stratify=y: Ensures both sets have same class proportions\")\n",
    "print(f\"      ‚Ä¢ Prevents bias toward one class in either set\")\n",
    "print(f\"      ‚Ä¢ Maintains the original dataset's balance\")\n",
    "print(f\"      ‚Ä¢ Critical for fair evaluation\")\n",
    "\n",
    "# Visualize the split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set visualization\n",
    "axes[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \n",
    "                c='red', alpha=0.6, s=50, label='Class 0', edgecolors='black')\n",
    "axes[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \n",
    "                c='blue', alpha=0.6, s=50, label='Class 1', edgecolors='black')\n",
    "axes[0].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[0].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[0].set_title(f'Training Set\\n({X_train.shape[0]} samples)', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Testing set visualization\n",
    "axes[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], \n",
    "                c='red', alpha=0.6, s=50, label='Class 0', edgecolors='black', marker='s')\n",
    "axes[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], \n",
    "                c='blue', alpha=0.6, s=50, label='Class 1', edgecolors='black', marker='s')\n",
    "axes[1].set_xlabel('Feature 1', fontsize=12)\n",
    "axes[1].set_ylabel('Feature 2', fontsize=12)\n",
    "axes[1].set_title(f'Testing Set\\n({X_test.shape[0]} samples)', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° NOTICE THE DIFFERENT MARKERS:\")\n",
    "print(f\"   ‚Ä¢ Training set: Circles (‚óè) - This is what SVM will learn from\")\n",
    "print(f\"   ‚Ä¢ Testing set: Squares (‚ñ†) - This is what SVM will be tested on\")\n",
    "print(f\"   ‚Ä¢ Both sets maintain similar patterns and distributions\")\n",
    "print(f\"   ‚Ä¢ This ensures our evaluation will be fair and representative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97dee0",
   "metadata": {},
   "source": [
    "## Splitting the data\n",
    "\n",
    "I need to split my data so I can actually test if my model works. It's like studying for an exam - I can't use the same questions to study AND test myself.\n",
    "\n",
    "**What I'm doing:**\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "```\n",
    "\n",
    "**Breaking this down:**\n",
    "- Take my X data and y labels\n",
    "- Put 70% into training sets (X_train, y_train) \n",
    "- Put 30% into testing sets (X_test, y_test)\n",
    "- random_state=42 makes it repeatable (same split every time)\n",
    "\n",
    "**Why 70/30 split:**\n",
    "Common rule of thumb. Need enough training data to learn patterns, but also enough test data to trust the results. Some people use 80/20, but 70/30 works fine for learning.\n",
    "\n",
    "**The random_state thing:**\n",
    "Without this, I'd get different random splits every time I run the code. Setting it to 42 (or any number) means I get the same split each time, so my results are consistent when I'm debugging.\n",
    "\n",
    "**What this gives me:**\n",
    "- X_train: 700 data points for training\n",
    "- X_test: 300 data points for testing  \n",
    "- y_train: 700 corresponding labels for training\n",
    "- y_test: 300 corresponding labels for testing\n",
    "\n",
    "Now I can train on the training set and see how well it does on completely new data (the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648808ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.127402</td>\n",
       "      <td>-1.165607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.714686</td>\n",
       "      <td>0.890897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266906</td>\n",
       "      <td>-1.312995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.577802</td>\n",
       "      <td>1.084275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.819035</td>\n",
       "      <td>0.923362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.420324</td>\n",
       "      <td>-1.463442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.897372</td>\n",
       "      <td>-0.806700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.274452</td>\n",
       "      <td>-1.117110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-0.695268</td>\n",
       "      <td>1.039606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.125787</td>\n",
       "      <td>-0.846542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.127402 -1.165607\n",
       "1   -0.714686  0.890897\n",
       "2    0.266906 -1.312995\n",
       "3   -0.577802  1.084275\n",
       "4   -1.819035  0.923362\n",
       "..        ...       ...\n",
       "995  0.420324 -1.463442\n",
       "996  1.897372 -0.806700\n",
       "997  0.274452 -1.117110\n",
       "998 -0.695268  1.039606\n",
       "999 -0.125787 -0.846542\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üöÄ SUPPORT VECTOR MACHINE: MODEL CREATION AND TRAINING\n",
    "# ======================================================\n",
    "\n",
    "# Time to create and train our SVM model!\n",
    "# We'll start with a Linear SVM to understand the basics\n",
    "\n",
    "print(\"ü§ñ CREATING LINEAR SUPPORT VECTOR MACHINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create SVM classifier with linear kernel\n",
    "svm_linear = SVC(\n",
    "    kernel='linear',        # Use linear decision boundary\n",
    "    C=1.0,                 # Regularization parameter (controls overfitting)\n",
    "    random_state=42        # For reproducible results\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Linear SVM Created Successfully!\")\n",
    "print(f\"   üìã Kernel: {svm_linear.kernel}\")\n",
    "print(f\"   ‚öñÔ∏è  Regularization (C): {svm_linear.C}\")\n",
    "print(f\"   üé≤ Random State: {svm_linear.random_state}\")\n",
    "\n",
    "print(f\"\\nüß† UNDERSTANDING SVM PARAMETERS:\")\n",
    "print(f\"   üî≤ kernel='linear': Creates straight-line decision boundaries\")\n",
    "print(f\"      ‚Ä¢ Best for linearly separable data\")\n",
    "print(f\"      ‚Ä¢ Fastest to train and predict\")\n",
    "print(f\"      ‚Ä¢ Most interpretable results\")\n",
    "print(f\"\")\n",
    "print(f\"   ‚öñÔ∏è  C=1.0: Controls the trade-off between:\")\n",
    "print(f\"      ‚Ä¢ Maximizing margin (larger gaps between classes)\")\n",
    "print(f\"      ‚Ä¢ Minimizing classification errors\")\n",
    "print(f\"      ‚Ä¢ Higher C = Less tolerant of errors (may overfit)\")\n",
    "print(f\"      ‚Ä¢ Lower C = More tolerant of errors (may underfit)\")\n",
    "print(f\"\")\n",
    "print(f\"   üéØ The SVM will find the 'maximum margin hyperplane':\")\n",
    "print(f\"      ‚Ä¢ Hyperplane = decision boundary that separates classes\")\n",
    "print(f\"      ‚Ä¢ Maximum margin = largest possible gap between classes\")\n",
    "print(f\"      ‚Ä¢ Support vectors = data points closest to the boundary\")\n",
    "\n",
    "# Now let's train the model\n",
    "print(f\"\\nüéì TRAINING THE SVM MODEL...\")\n",
    "print(\"   (Finding the optimal decision boundary)\")\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the SVM model\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Training Complete!\")\n",
    "print(f\"   ‚è±Ô∏è  Training time: {training_time:.4f} seconds\")\n",
    "print(f\"   üìä Training samples used: {X_train.shape[0]}\")\n",
    "print(f\"   üéØ Features used: {X_train.shape[1]}\")\n",
    "\n",
    "# Get information about the trained model\n",
    "print(f\"\\nüìà TRAINED MODEL INFORMATION:\")\n",
    "print(f\"   üéØ Support Vectors: {svm_linear.n_support_}\")\n",
    "print(f\"      ‚Ä¢ Class 0: {svm_linear.n_support_[0]} support vectors\")\n",
    "print(f\"      ‚Ä¢ Class 1: {svm_linear.n_support_[1]} support vectors\")\n",
    "print(f\"      ‚Ä¢ Total: {sum(svm_linear.n_support_)} support vectors\")\n",
    "print(f\"\")\n",
    "print(f\"   üî¢ Total training samples: {X_train.shape[0]}\")\n",
    "print(f\"   üìä Support vector ratio: {sum(svm_linear.n_support_)/X_train.shape[0]:.1%}\")\n",
    "print(f\"   {'‚úÖ Efficient' if sum(svm_linear.n_support_)/X_train.shape[0] < 0.3 else '‚ö†Ô∏è Many support vectors'}\")\n",
    "\n",
    "print(f\"\\nüí° WHAT JUST HAPPENED:\")\n",
    "print(f\"   1. üîç SVM examined all {X_train.shape[0]} training points\")\n",
    "print(f\"   2. üìè Found the decision boundary with maximum margin\")\n",
    "print(f\"   3. üéØ Identified {sum(svm_linear.n_support_)} support vectors\")\n",
    "print(f\"   4. ‚öñÔ∏è  Balanced margin maximization with error minimization\")\n",
    "print(f\"   5. üèÅ Model is now ready to make predictions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe1783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.127402\n",
       "1     -0.714686\n",
       "2      0.266906\n",
       "3     -0.577802\n",
       "4     -1.819035\n",
       "         ...   \n",
       "995    0.420324\n",
       "996    1.897372\n",
       "997    0.274452\n",
       "998   -0.695268\n",
       "999   -0.125787\n",
       "Name: 0, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîÆ MAKING PREDICTIONS WITH OUR TRAINED SVM\n",
    "# ==========================================\n",
    "\n",
    "# Now that our SVM is trained, let's use it to make predictions on unseen data\n",
    "\n",
    "print(\"üîÆ MAKING PREDICTIONS ON TEST DATA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Make predictions on the test set\n",
    "start_time = time.time()\n",
    "y_pred = svm_linear.predict(X_test)\n",
    "prediction_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Predictions Complete!\")\n",
    "print(f\"   ‚è±Ô∏è  Prediction time: {prediction_time:.6f} seconds\")\n",
    "print(f\"   üìä Test samples: {X_test.shape[0]}\")\n",
    "print(f\"   ‚ö° Speed: {X_test.shape[0]/prediction_time:.0f} predictions/second\")\n",
    "\n",
    "print(f\"\\nüìã PREDICTION RESULTS SUMMARY:\")\n",
    "print(f\"   üéØ Predicted Classes: {sorted(set(y_pred))}\")\n",
    "print(f\"   üìä Prediction Counts: {Counter(y_pred)}\")\n",
    "\n",
    "# Let's also get prediction probabilities (confidence scores)\n",
    "# Note: SVM doesn't naturally output probabilities, but we can enable this\n",
    "print(f\"\\nüéØ GETTING PREDICTION CONFIDENCE SCORES...\")\n",
    "\n",
    "# Create a new SVM with probability estimation enabled\n",
    "svm_with_proba = SVC(kernel='linear', C=1.0, random_state=42, probability=True)\n",
    "svm_with_proba.fit(X_train, y_train)\n",
    "y_proba = svm_with_proba.predict_proba(X_test)\n",
    "\n",
    "print(f\"‚úÖ Confidence scores calculated!\")\n",
    "print(f\"   üìä Shape of probability matrix: {y_proba.shape}\")\n",
    "print(f\"   üìã Each row: [P(Class 0), P(Class 1)] for one test sample\")\n",
    "\n",
    "# Show some example predictions with confidence\n",
    "print(f\"\\nüîç SAMPLE PREDICTIONS WITH CONFIDENCE:\")\n",
    "print(\"Sample | True | Pred | Confidence Class 0 | Confidence Class 1 | Decision\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for i in range(min(10, len(X_test))):  # Show first 10 predictions\n",
    "    true_class = y_test[i]\n",
    "    pred_class = y_pred[i]\n",
    "    conf_0 = y_proba[i, 0]\n",
    "    conf_1 = y_proba[i, 1]\n",
    "    decision = \"‚úÖ Correct\" if true_class == pred_class else \"‚ùå Wrong\"\n",
    "    \n",
    "    print(f\"{i+1:6d} | {true_class:4d} | {pred_class:4d} | {conf_0:12.3f} | {conf_1:12.3f} | {decision}\")\n",
    "\n",
    "# Analyze confidence distribution\n",
    "high_confidence = np.sum(np.max(y_proba, axis=1) > 0.8)\n",
    "medium_confidence = np.sum((np.max(y_proba, axis=1) > 0.6) & (np.max(y_proba, axis=1) <= 0.8))\n",
    "low_confidence = np.sum(np.max(y_proba, axis=1) <= 0.6)\n",
    "\n",
    "print(f\"\\nüìä CONFIDENCE DISTRIBUTION:\")\n",
    "print(f\"   üü¢ High confidence (>80%): {high_confidence} predictions ({high_confidence/len(y_pred):.1%})\")\n",
    "print(f\"   üü° Medium confidence (60-80%): {medium_confidence} predictions ({medium_confidence/len(y_pred):.1%})\")\n",
    "print(f\"   üî¥ Low confidence (<60%): {low_confidence} predictions ({low_confidence/len(y_pred):.1%})\")\n",
    "\n",
    "print(f\"\\nüí° UNDERSTANDING THE PREDICTIONS:\")\n",
    "print(f\"   üîÆ Each prediction is based on which side of the decision boundary a point falls\")\n",
    "print(f\"   üìè Distance from boundary determines confidence:\")\n",
    "print(f\"      ‚Ä¢ Points far from boundary = High confidence\")\n",
    "print(f\"      ‚Ä¢ Points near boundary = Low confidence\")\n",
    "print(f\"   üéØ SVM's strength: Clear decisions even with complex data\")\n",
    "print(f\"   ‚ö° Fast predictions: Only depends on support vectors, not all training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea2c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -1.165607\n",
       "1      0.890897\n",
       "2     -1.312995\n",
       "3      1.084275\n",
       "4      0.923362\n",
       "         ...   \n",
       "995   -1.463442\n",
       "996   -0.806700\n",
       "997   -1.117110\n",
       "998    1.039606\n",
       "999   -0.846542\n",
       "Name: 1, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üìä MODEL EVALUATION: HOW WELL DID OUR SVM PERFORM?\n",
    "# ==================================================\n",
    "\n",
    "# Let's evaluate our SVM's performance using multiple metrics\n",
    "\n",
    "print(\"üìä COMPREHENSIVE MODEL EVALUATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Basic Accuracy Score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"üéØ ACCURACY: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Out of {len(y_test)} test samples, {sum(y_test == y_pred)} were classified correctly\")\n",
    "print(f\"   ‚Ä¢ This means {sum(y_test != y_pred)} samples were misclassified\")\n",
    "\n",
    "# 2. Classification Report (Precision, Recall, F1-Score)\n",
    "print(f\"\\nüìã DETAILED CLASSIFICATION REPORT:\")\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"üîç UNDERSTANDING THE METRICS:\")\n",
    "print(f\"   üìä Precision: How many predicted positives were actually positive?\")\n",
    "print(f\"      ‚Ä¢ Class 0: {report['0']['precision']:.3f} - Of all predicted Class 0, {report['0']['precision']*100:.1f}% were correct\")\n",
    "print(f\"      ‚Ä¢ Class 1: {report['1']['precision']:.3f} - Of all predicted Class 1, {report['1']['precision']*100:.1f}% were correct\")\n",
    "print(f\"\")\n",
    "print(f\"   üéØ Recall (Sensitivity): How many actual positives were found?\")\n",
    "print(f\"      ‚Ä¢ Class 0: {report['0']['recall']:.3f} - Found {report['0']['recall']*100:.1f}% of all actual Class 0\")\n",
    "print(f\"      ‚Ä¢ Class 1: {report['1']['recall']:.3f} - Found {report['1']['recall']*100:.1f}% of all actual Class 1\")\n",
    "print(f\"\")\n",
    "print(f\"   ‚öñÔ∏è  F1-Score: Harmonic mean of Precision and Recall\")\n",
    "print(f\"      ‚Ä¢ Class 0: {report['0']['f1-score']:.3f}\")\n",
    "print(f\"      ‚Ä¢ Class 1: {report['1']['f1-score']:.3f}\")\n",
    "print(f\"      ‚Ä¢ Overall: {report['macro avg']['f1-score']:.3f}\")\n",
    "\n",
    "# 3. Confusion Matrix Analysis\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nüé≠ CONFUSION MATRIX ANALYSIS:\")\n",
    "print(f\"   Confusion Matrix:\")\n",
    "print(f\"   {cm}\")\n",
    "print(f\"\")\n",
    "print(f\"   üìä Breaking it down:\")\n",
    "print(f\"      ‚Ä¢ True Negatives (TN):  {cm[0,0]} - Correctly predicted Class 0\")\n",
    "print(f\"      ‚Ä¢ False Positives (FP): {cm[0,1]} - Wrongly predicted Class 1 (Type I error)\")\n",
    "print(f\"      ‚Ä¢ False Negatives (FN): {cm[1,0]} - Wrongly predicted Class 0 (Type II error)\")\n",
    "print(f\"      ‚Ä¢ True Positives (TP):  {cm[1,1]} - Correctly predicted Class 1\")\n",
    "\n",
    "# Calculate error rates\n",
    "total_errors = cm[0,1] + cm[1,0]\n",
    "error_rate = total_errors / len(y_test)\n",
    "\n",
    "print(f\"\\n‚ùå ERROR ANALYSIS:\")\n",
    "print(f\"   ‚Ä¢ Total errors: {total_errors} out of {len(y_test)} samples\")\n",
    "print(f\"   ‚Ä¢ Error rate: {error_rate:.4f} ({error_rate*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Type I errors (False Positives): {cm[0,1]}\")\n",
    "print(f\"   ‚Ä¢ Type II errors (False Negatives): {cm[1,0]}\")\n",
    "\n",
    "# Performance assessment\n",
    "if accuracy > 0.9:\n",
    "    performance = \"üåü Excellent\"\n",
    "elif accuracy > 0.8:\n",
    "    performance = \"‚úÖ Good\"\n",
    "elif accuracy > 0.7:\n",
    "    performance = \"‚ö†Ô∏è Fair\"\n",
    "else:\n",
    "    performance = \"‚ùå Poor\"\n",
    "\n",
    "print(f\"\\nüèÜ OVERALL PERFORMANCE ASSESSMENT: {performance}\")\n",
    "print(f\"   üìà Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"   üéØ This SVM model {'performs very well' if accuracy > 0.8 else 'needs improvement'}\")\n",
    "print(f\"   üí° {'Great job! The linear SVM found a good decision boundary.' if accuracy > 0.8 else 'Consider trying non-linear kernels or tuning parameters.'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87394d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='0', ylabel='1'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üé® VISUALIZING THE SVM DECISION BOUNDARY\n",
    "# ========================================\n",
    "\n",
    "# One of the best ways to understand SVM is to visualize its decision boundary\n",
    "# Let's create a beautiful plot showing how SVM separates our classes\n",
    "\n",
    "print(\"üé® CREATING DECISION BOUNDARY VISUALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def plot_svm_decision_boundary(X, y, model, title=\"SVM Decision Boundary\"):\n",
    "    \"\"\"\n",
    "    Visualize SVM decision boundary with support vectors highlighted\n",
    "    \"\"\"\n",
    "    # Create a mesh grid for plotting decision boundary\n",
    "    h = 0.02  # Step size in the mesh\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Make predictions on the mesh grid\n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict(mesh_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "    plt.contour(xx, yy, Z, colors='black', linestyles='--', linewidths=1)\n",
    "    \n",
    "    # Plot all data points\n",
    "    scatter_0 = plt.scatter(X[y == 0, 0], X[y == 0, 1], c='red', s=50, \n",
    "                           alpha=0.8, edgecolors='black', label='Class 0')\n",
    "    scatter_1 = plt.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', s=50, \n",
    "                           alpha=0.8, edgecolors='black', label='Class 1')\n",
    "    \n",
    "    # Highlight support vectors\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                   s=200, facecolors='none', edgecolors='yellow', linewidths=3,\n",
    "                   label=f'Support Vectors ({len(model.support_vectors_)})')\n",
    "    \n",
    "    plt.xlabel('Feature 1', fontsize=12)\n",
    "    plt.ylabel('Feature 2', fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "# Plot the decision boundary for our linear SVM\n",
    "fig = plot_svm_decision_boundary(X_train, y_train, svm_linear, \n",
    "                                \"Linear SVM Decision Boundary\\n(Training Data with Support Vectors)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç UNDERSTANDING THE VISUALIZATION:\")\n",
    "print(\"   üé® Background colors: Show prediction regions\")\n",
    "print(\"      ‚Ä¢ Red region: Where SVM predicts Class 0\")\n",
    "print(\"      ‚Ä¢ Blue region: Where SVM predicts Class 1\")\n",
    "print(\"   \")\n",
    "print(\"   ‚ö´ Black dashed line: The decision boundary (hyperplane)\")\n",
    "print(\"      ‚Ä¢ Points on one side ‚Üí Class 0\")\n",
    "print(\"      ‚Ä¢ Points on other side ‚Üí Class 1\")\n",
    "print(\"      ‚Ä¢ This is the 'maximum margin' boundary SVM found\")\n",
    "print(\"   \")\n",
    "print(\"   üü° Yellow circles: Support Vectors\")\n",
    "print(f\"      ‚Ä¢ These {len(svm_linear.support_vectors_)} points define the decision boundary\")\n",
    "print(\"      ‚Ä¢ If we removed other points, boundary would stay the same\")\n",
    "print(\"      ‚Ä¢ These are the 'critical' points SVM focuses on\")\n",
    "print(\"   \")\n",
    "print(\"   üî¥üîµ Colored points: Training data\")\n",
    "print(\"      ‚Ä¢ Red = Class 0, Blue = Class 1\")\n",
    "print(\"      ‚Ä¢ SVM found the best way to separate these\")\n",
    "\n",
    "# Create a second plot showing training vs test performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# Training data plot\n",
    "ax1 = axes[0]\n",
    "h = 0.02\n",
    "x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = svm_linear.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax1.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "ax1.contour(xx, yy, Z, colors='black', linestyles='--', linewidths=1)\n",
    "ax1.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c='red', s=50, alpha=0.8, edgecolors='black', label='Class 0')\n",
    "ax1.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c='blue', s=50, alpha=0.8, edgecolors='black', label='Class 1')\n",
    "ax1.scatter(svm_linear.support_vectors_[:, 0], svm_linear.support_vectors_[:, 1], s=200, facecolors='none', edgecolors='yellow', linewidths=3, label='Support Vectors')\n",
    "ax1.set_xlabel('Feature 1')\n",
    "ax1.set_ylabel('Feature 2')\n",
    "ax1.set_title('Training Data\\n(Where SVM Learned)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Test data plot\n",
    "ax2 = axes[1]\n",
    "x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = svm_linear.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax2.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.RdYlBu)\n",
    "ax2.contour(xx, yy, Z, colors='black', linestyles='--', linewidths=1)\n",
    "\n",
    "# Color test points by correctness\n",
    "correct_mask = y_test == y_pred\n",
    "incorrect_mask = ~correct_mask\n",
    "\n",
    "ax2.scatter(X_test[correct_mask & (y_test == 0), 0], X_test[correct_mask & (y_test == 0), 1], \n",
    "           c='red', s=50, alpha=0.8, edgecolors='black', marker='o', label='Correct Class 0')\n",
    "ax2.scatter(X_test[correct_mask & (y_test == 1), 0], X_test[correct_mask & (y_test == 1), 1], \n",
    "           c='blue', s=50, alpha=0.8, edgecolors='black', marker='o', label='Correct Class 1')\n",
    "ax2.scatter(X_test[incorrect_mask, 0], X_test[incorrect_mask, 1], \n",
    "           c='orange', s=100, alpha=0.8, edgecolors='red', marker='X', label='Misclassified')\n",
    "\n",
    "ax2.set_xlabel('Feature 1')\n",
    "ax2.set_ylabel('Feature 2')\n",
    "ax2.set_title('Test Data\\n(How SVM Performs on Unseen Data)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° COMPARING TRAINING VS TEST PERFORMANCE:\")\n",
    "print(f\"   üéì Left plot: Training data - This is what SVM learned from\")\n",
    "print(f\"   üß™ Right plot: Test data - This shows how well SVM generalizes\")\n",
    "print(f\"   ‚úÖ Correct predictions: Circle markers\")\n",
    "print(f\"   ‚ùå Misclassified points: X markers in orange\")\n",
    "print(f\"   üìä The decision boundary is the same in both plots\")\n",
    "print(f\"       (SVM uses the same learned boundary for new data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992cb1d",
   "metadata": {},
   "source": [
    "## Visualizing the classification data\n",
    "\n",
    "This scatter plot shows my synthetic classification dataset:\n",
    "\n",
    "**What I'm seeing:**\n",
    "- **X-axis**: Feature 1 values\n",
    "- **Y-axis**: Feature 2 values  \n",
    "- **Colors**: Different classes (0 and 1)\n",
    "- **Clusters**: Each class has 2 clusters (because n_clusters_per_class=2)\n",
    "\n",
    "**Why this visualization matters:**\n",
    "- Shows if classes are separable (can draw a line between them)\n",
    "- Reveals the complexity of the decision boundary needed\n",
    "- Helps me choose the right kernel (linear vs RBF)\n",
    "- 2 clusters per class makes it more challenging and realistic\n",
    "\n",
    "**What to look for:**\n",
    "- **Clear separation**: Linear kernel might work\n",
    "- **Mixed/overlapping**: Might need RBF kernel  \n",
    "- **Complex patterns**: More sophisticated approach needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåü ADVANCED SVM: RBF KERNEL FOR NON-LINEAR CLASSIFICATION\n",
    "# ========================================================\n",
    "\n",
    "# Linear SVM works great for linearly separable data, but what about complex patterns?\n",
    "# Let's explore the power of the RBF (Radial Basis Function) kernel!\n",
    "\n",
    "print(\"üåü CREATING RBF KERNEL SVM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create SVM with RBF kernel\n",
    "svm_rbf = SVC(\n",
    "    kernel='rbf',           # Radial Basis Function kernel\n",
    "    C=1.0,                 # Regularization parameter\n",
    "    gamma='scale',         # Kernel coefficient (auto-calculated)\n",
    "    random_state=42,       # For reproducible results\n",
    "    probability=True       # Enable probability estimates\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RBF SVM Created Successfully!\")\n",
    "print(f\"   üîÆ Kernel: {svm_rbf.kernel}\")\n",
    "print(f\"   ‚öñÔ∏è  Regularization (C): {svm_rbf.C}\")\n",
    "print(f\"   üìä Gamma: {svm_rbf.gamma}\")\n",
    "print(f\"   üé≤ Random State: {svm_rbf.random_state}\")\n",
    "\n",
    "print(f\"\\nüß† UNDERSTANDING RBF KERNEL:\")\n",
    "print(f\"   üåÄ RBF = Radial Basis Function (also called Gaussian kernel)\")\n",
    "print(f\"   üìê Creates circular/curved decision boundaries\")\n",
    "print(f\"   üéØ Can separate complex, non-linear patterns\")\n",
    "print(f\"   üìä Transforms data to higher-dimensional space\")\n",
    "print(f\"\")\n",
    "print(f\"   üîß Key Parameters:\")\n",
    "print(f\"      ‚Ä¢ C: Controls overfitting (same as linear SVM)\")\n",
    "print(f\"      ‚Ä¢ gamma: Controls 'influence radius' of each training point\")\n",
    "print(f\"        - High gamma: Tight fit (may overfit)\")\n",
    "print(f\"        - Low gamma: Smooth boundaries (may underfit)\")\n",
    "print(f\"        - 'scale': gamma = 1/(n_features * X.var())\")\n",
    "\n",
    "# Train the RBF SVM\n",
    "print(f\"\\nüéì TRAINING RBF SVM...\")\n",
    "print(\"   (This might take slightly longer than linear SVM)\")\n",
    "\n",
    "start_time = time.time()\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "training_time_rbf = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ Training Complete!\")\n",
    "print(f\"   ‚è±Ô∏è  Training time: {training_time_rbf:.4f} seconds\")\n",
    "print(f\"   üìä Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   üîÆ Kernel transformations: Infinite dimensional!\")\n",
    "\n",
    "# Get model information\n",
    "print(f\"\\nüìà TRAINED RBF MODEL INFORMATION:\")\n",
    "print(f\"   üéØ Support Vectors: {svm_rbf.n_support_}\")\n",
    "print(f\"      ‚Ä¢ Class 0: {svm_rbf.n_support_[0]} support vectors\")\n",
    "print(f\"      ‚Ä¢ Class 1: {svm_rbf.n_support_[1]} support vectors\")\n",
    "print(f\"      ‚Ä¢ Total: {sum(svm_rbf.n_support_)} support vectors\")\n",
    "print(f\"\")\n",
    "print(f\"   üìä Support vector ratio: {sum(svm_rbf.n_support_)/X_train.shape[0]:.1%}\")\n",
    "print(f\"   üîç Gamma value used: {svm_rbf.gamma}\")\n",
    "\n",
    "# Compare with linear SVM\n",
    "print(f\"\\n‚öñÔ∏è  COMPARISON: LINEAR vs RBF SVM:\")\n",
    "print(f\"   üìä Support Vectors:\")\n",
    "print(f\"      ‚Ä¢ Linear SVM: {sum(svm_linear.n_support_)} ({sum(svm_linear.n_support_)/X_train.shape[0]:.1%})\")\n",
    "print(f\"      ‚Ä¢ RBF SVM:    {sum(svm_rbf.n_support_)} ({sum(svm_rbf.n_support_)/X_train.shape[0]:.1%})\")\n",
    "print(f\"\")\n",
    "print(f\"   ‚è±Ô∏è  Training Time:\")\n",
    "print(f\"      ‚Ä¢ Linear SVM: {training_time:.4f} seconds\")\n",
    "print(f\"      ‚Ä¢ RBF SVM:    {training_time_rbf:.4f} seconds\")\n",
    "print(f\"\")\n",
    "print(f\"   üîÑ Complexity:\")\n",
    "print(f\"      ‚Ä¢ Linear: Simple, interpretable boundaries\")\n",
    "print(f\"      ‚Ä¢ RBF: Complex, flexible boundaries\")\n",
    "\n",
    "print(f\"\\nüí° WHY USE RBF KERNEL:\")\n",
    "print(f\"   üéØ When linear boundaries aren't enough\")\n",
    "print(f\"   üåÄ Can capture complex, curved patterns\")\n",
    "print(f\"   üìà Often better accuracy on complex datasets\")\n",
    "print(f\"   ‚ö†Ô∏è  But: More prone to overfitting\")\n",
    "print(f\"   üîç Requires careful parameter tuning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f124f",
   "metadata": {},
   "source": [
    "## Actually splitting the data\n",
    "\n",
    "Ok so I understand the concept, now I need to actually do it. Looking at the code:\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)\n",
    "```\n",
    "\n",
    "Pretty much the same as before but with test_size=0.30 instead of 0.3 (same thing) and random_state=1 instead of 42. The random_state number doesn't really matter as long as it's consistent.\n",
    "\n",
    "So now I have:\n",
    "- 70% of my 1000 points (700) for training\n",
    "- 30% of my 1000 points (300) for testing\n",
    "\n",
    "This is a good split for learning. I'll train the SVM on the 700 points and see how well it does on the 300 it's never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92c9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîÆ RBF SVM PREDICTIONS AND EVALUATION\n",
    "# ====================================\n",
    "\n",
    "# Let's see how our RBF SVM performs compared to the linear version\n",
    "\n",
    "print(\"üîÆ MAKING PREDICTIONS WITH RBF SVM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Make predictions with RBF SVM\n",
    "start_time = time.time()\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "y_proba_rbf = svm_rbf.predict_proba(X_test)\n",
    "prediction_time_rbf = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ RBF Predictions Complete!\")\n",
    "print(f\"   ‚è±Ô∏è  Prediction time: {prediction_time_rbf:.6f} seconds\")\n",
    "print(f\"   üìä Test samples: {X_test.shape[0]}\")\n",
    "print(f\"   ‚ö° Speed: {X_test.shape[0]/prediction_time_rbf:.0f} predictions/second\")\n",
    "\n",
    "# Evaluate RBF SVM performance\n",
    "accuracy_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "report_rbf = classification_report(y_test, y_pred_rbf, output_dict=True)\n",
    "\n",
    "print(f\"\\nüìä RBF SVM PERFORMANCE:\")\n",
    "print(f\"   üéØ Accuracy: {accuracy_rbf:.4f} ({accuracy_rbf*100:.2f}%)\")\n",
    "print(f\"   üìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rbf))\n",
    "\n",
    "# Detailed comparison between Linear and RBF SVM\n",
    "print(f\"\\n‚öñÔ∏è  DETAILED COMPARISON: LINEAR vs RBF SVM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Metric':<20} {'Linear SVM':<15} {'RBF SVM':<15} {'Winner':<10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Accuracy':<20} {accuracy:.4f} ({accuracy*100:.1f}%){'':<3} {accuracy_rbf:.4f} ({accuracy_rbf*100:.1f}%){'':<3} {'RBF' if accuracy_rbf > accuracy else 'Linear' if accuracy > accuracy_rbf else 'Tie':<10}\")\n",
    "\n",
    "# Compare precision, recall, f1 for each class\n",
    "for class_label in ['0', '1']:\n",
    "    print(f\"Class {class_label} Precision{'':<6} {report[class_label]['precision']:.4f}{'':<8} {report_rbf[class_label]['precision']:.4f}{'':<8} {'RBF' if report_rbf[class_label]['precision'] > report[class_label]['precision'] else 'Linear' if report[class_label]['precision'] > report_rbf[class_label]['precision'] else 'Tie':<10}\")\n",
    "    print(f\"Class {class_label} Recall{'':<9} {report[class_label]['recall']:.4f}{'':<8} {report_rbf[class_label]['recall']:.4f}{'':<8} {'RBF' if report_rbf[class_label]['recall'] > report[class_label]['recall'] else 'Linear' if report[class_label]['recall'] > report_rbf[class_label]['recall'] else 'Tie':<10}\")\n",
    "\n",
    "print(f\"{'Support Vectors':<20} {sum(svm_linear.n_support_):<15} {sum(svm_rbf.n_support_):<15} {'Linear' if sum(svm_linear.n_support_) < sum(svm_rbf.n_support_) else 'RBF':<10}\")\n",
    "print(f\"{'Training Time':<20} {training_time:.4f}s{'':<8} {training_time_rbf:.4f}s{'':<8} {'Linear' if training_time < training_time_rbf else 'RBF':<10}\")\n",
    "\n",
    "# Analyze confidence differences\n",
    "high_conf_linear = np.sum(np.max(y_proba, axis=1) > 0.8)\n",
    "high_conf_rbf = np.sum(np.max(y_proba_rbf, axis=1) > 0.8)\n",
    "\n",
    "print(f\"\\nüîç CONFIDENCE ANALYSIS:\")\n",
    "print(f\"   üìä High Confidence Predictions (>80%):\")\n",
    "print(f\"      ‚Ä¢ Linear SVM: {high_conf_linear} out of {len(y_pred)} ({high_conf_linear/len(y_pred):.1%})\")\n",
    "print(f\"      ‚Ä¢ RBF SVM:    {high_conf_rbf} out of {len(y_pred_rbf)} ({high_conf_rbf/len(y_pred_rbf):.1%})\")\n",
    "\n",
    "# Show disagreements between models\n",
    "disagreements = (y_pred != y_pred_rbf)\n",
    "num_disagreements = np.sum(disagreements)\n",
    "\n",
    "print(f\"\\nü§î MODEL DISAGREEMENTS:\")\n",
    "print(f\"   üìä Cases where Linear and RBF predict differently: {num_disagreements}\")\n",
    "print(f\"   üìà Agreement rate: {(len(y_pred) - num_disagreements)/len(y_pred):.1%}\")\n",
    "\n",
    "if num_disagreements > 0:\n",
    "    print(f\"\\n   üîç Sample disagreements:\")\n",
    "    print(\"   Sample | True | Linear | RBF | Linear Conf | RBF Conf | Correct?\")\n",
    "    print(\"   \" + \"-\" * 65)\n",
    "    disagreement_indices = np.where(disagreements)[0][:5]  # Show first 5\n",
    "    \n",
    "    for idx in disagreement_indices:\n",
    "        true_label = y_test[idx]\n",
    "        linear_pred = y_pred[idx]\n",
    "        rbf_pred = y_pred_rbf[idx]\n",
    "        linear_conf = np.max(y_proba[idx])\n",
    "        rbf_conf = np.max(y_proba_rbf[idx])\n",
    "        linear_correct = \"‚úÖ\" if linear_pred == true_label else \"‚ùå\"\n",
    "        rbf_correct = \"‚úÖ\" if rbf_pred == true_label else \"‚ùå\"\n",
    "        \n",
    "        print(f\"   {idx+1:6d} | {true_label:4d} | {linear_pred:6d} | {rbf_pred:3d} | {linear_conf:11.3f} | {rbf_conf:8.3f} | L:{linear_correct} R:{rbf_correct}\")\n",
    "\n",
    "# Overall recommendation\n",
    "if accuracy_rbf > accuracy + 0.02:  # RBF significantly better\n",
    "    recommendation = \"üåü RBF SVM is clearly better for this dataset\"\n",
    "elif accuracy > accuracy_rbf + 0.02:  # Linear significantly better\n",
    "    recommendation = \"‚ö° Linear SVM is sufficient and more efficient\"\n",
    "else:  # Close performance\n",
    "    recommendation = \"‚öñÔ∏è Both models perform similarly - choose based on interpretability needs\"\n",
    "\n",
    "print(f\"\\nüèÜ RECOMMENDATION: {recommendation}\")\n",
    "print(f\"   üí° Consider:\")\n",
    "print(f\"      ‚Ä¢ Interpretability: Linear SVM is more interpretable\")\n",
    "print(f\"      ‚Ä¢ Complexity: RBF can capture more complex patterns\")\n",
    "print(f\"      ‚Ä¢ Speed: Linear SVM is typically faster\")\n",
    "print(f\"      ‚Ä¢ Overfitting: RBF is more prone to overfitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® VISUALIZING RBF SVM DECISION BOUNDARY\n",
    "# ========================================\n",
    "\n",
    "# Let's see how the RBF kernel creates more complex, curved decision boundaries\n",
    "\n",
    "print(\"üé® CREATING RBF DECISION BOUNDARY VISUALIZATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create side-by-side comparison of Linear vs RBF decision boundaries\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "def plot_detailed_decision_boundary(X, y, model, ax, title, kernel_type):\n",
    "    \"\"\"Enhanced decision boundary plotting with detailed annotations\"\"\"\n",
    "    \n",
    "    # Create mesh grid\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Get predictions and decision function values\n",
    "    mesh_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict(mesh_points)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Also get decision function for margin visualization\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        decision_values = model.decision_function(mesh_points)\n",
    "        decision_values = decision_values.reshape(xx.shape)\n",
    "    \n",
    "    # Plot decision regions\n",
    "    im = ax.contourf(xx, yy, Z, levels=1, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    # Plot decision boundary and margins\n",
    "    ax.contour(xx, yy, Z, colors='black', linestyles='-', linewidths=2, levels=[0.5])\n",
    "    \n",
    "    if hasattr(model, 'decision_function'):\n",
    "        # Plot margins (decision function = ¬±1)\n",
    "        ax.contour(xx, yy, decision_values, colors='gray', linestyles='--', \n",
    "                  linewidths=1, levels=[-1, 1], alpha=0.7)\n",
    "    \n",
    "    # Plot data points\n",
    "    scatter_0 = ax.scatter(X[y == 0, 0], X[y == 0, 1], c='red', s=60, \n",
    "                          alpha=0.8, edgecolors='black', linewidths=1, label='Class 0')\n",
    "    scatter_1 = ax.scatter(X[y == 1, 0], X[y == 1, 1], c='blue', s=60, \n",
    "                          alpha=0.8, edgecolors='black', linewidths=1, label='Class 1')\n",
    "    \n",
    "    # Highlight support vectors\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                  s=300, facecolors='none', edgecolors='yellow', linewidths=4,\n",
    "                  label=f'Support Vectors ({len(model.support_vectors_)})')\n",
    "    \n",
    "    ax.set_xlabel('Feature 1', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Feature 2', fontsize=12, fontweight='bold')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add kernel-specific annotations\n",
    "    if kernel_type == 'linear':\n",
    "        ax.text(0.02, 0.98, 'Straight line\\ndecision boundary', \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    else:\n",
    "        ax.text(0.02, 0.98, 'Curved\\ndecision boundary', \n",
    "                transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "# Plot Linear SVM\n",
    "plot_detailed_decision_boundary(X_train, y_train, svm_linear, axes[0], \n",
    "                               'Linear SVM Decision Boundary\\n(Straight Lines Only)', 'linear')\n",
    "\n",
    "# Plot RBF SVM  \n",
    "plot_detailed_decision_boundary(X_train, y_train, svm_rbf, axes[1], \n",
    "                               'RBF SVM Decision Boundary\\n(Curved Boundaries)', 'rbf')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üîç COMPARING THE DECISION BOUNDARIES:\")\n",
    "print(\"   üìê Linear SVM (Left):\")\n",
    "print(\"      ‚Ä¢ Creates straight-line decision boundaries\")\n",
    "print(\"      ‚Ä¢ Simple, interpretable separation\")\n",
    "print(f\"      ‚Ä¢ Uses {sum(svm_linear.n_support_)} support vectors\")\n",
    "print(\"      ‚Ä¢ Fast training and prediction\")\n",
    "print()\n",
    "print(\"   üåÄ RBF SVM (Right):\")\n",
    "print(\"      ‚Ä¢ Creates curved, flexible decision boundaries\")\n",
    "print(\"      ‚Ä¢ Can adapt to complex data patterns\")\n",
    "print(f\"      ‚Ä¢ Uses {sum(svm_rbf.n_support_)} support vectors\")\n",
    "print(\"      ‚Ä¢ More computational complexity\")\n",
    "\n",
    "# Create a detailed analysis plot showing prediction confidence\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Function to plot confidence regions\n",
    "def plot_confidence_regions(model, ax, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        Z_proba = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z_confidence = np.max(Z_proba, axis=1)\n",
    "        Z_confidence = Z_confidence.reshape(xx.shape)\n",
    "        \n",
    "        # Plot confidence as contours\n",
    "        conf_levels = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "        cs = ax.contourf(xx, yy, Z_confidence, levels=conf_levels, \n",
    "                        cmap='viridis', alpha=0.6)\n",
    "        ax.contour(xx, yy, Z_confidence, levels=conf_levels, \n",
    "                  colors='white', linestyles='-', linewidths=0.5)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(cs, ax=ax)\n",
    "        cbar.set_label('Prediction Confidence', rotation=270, labelpad=20)\n",
    "    \n",
    "    # Plot data points\n",
    "    ax.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], \n",
    "              c='red', s=40, alpha=0.8, edgecolors='black', label='Class 0')\n",
    "    ax.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], \n",
    "              c='blue', s=40, alpha=0.8, edgecolors='black', label='Class 1')\n",
    "    \n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.legend()\n",
    "\n",
    "# Top row: Confidence regions\n",
    "plot_confidence_regions(svm_linear, axes[0, 0], 'Linear SVM\\nPrediction Confidence')\n",
    "plot_confidence_regions(svm_rbf, axes[0, 1], 'RBF SVM\\nPrediction Confidence')\n",
    "\n",
    "# Bottom row: Test performance visualization\n",
    "def plot_test_results(X_test, y_test, y_pred, ax, title):\n",
    "    correct = (y_test == y_pred)\n",
    "    \n",
    "    # Plot correct predictions\n",
    "    ax.scatter(X_test[correct & (y_test == 0), 0], X_test[correct & (y_test == 0), 1],\n",
    "              c='red', s=60, alpha=0.8, edgecolors='black', marker='o', label='Correct Class 0')\n",
    "    ax.scatter(X_test[correct & (y_test == 1), 0], X_test[correct & (y_test == 1), 1],\n",
    "              c='blue', s=60, alpha=0.8, edgecolors='black', marker='o', label='Correct Class 1')\n",
    "    \n",
    "    # Plot incorrect predictions\n",
    "    ax.scatter(X_test[~correct, 0], X_test[~correct, 1],\n",
    "              c='orange', s=100, alpha=0.9, edgecolors='red', marker='X', \n",
    "              linewidths=2, label=f'Errors ({np.sum(~correct)})')\n",
    "    \n",
    "    ax.set_title(f'{title}\\nAccuracy: {np.mean(correct):.1%}', fontweight='bold')\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plot_test_results(X_test, y_test, y_pred, axes[1, 0], 'Linear SVM Test Results')\n",
    "plot_test_results(X_test, y_test, y_pred_rbf, axes[1, 1], 'RBF SVM Test Results')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° CONFIDENCE AND PERFORMANCE INSIGHTS:\")\n",
    "print(\"   üé® Top row: Shows prediction confidence across the feature space\")\n",
    "print(\"      ‚Ä¢ Darker regions = Higher confidence\")\n",
    "print(\"      ‚Ä¢ Lighter regions = Lower confidence (near decision boundary)\")\n",
    "print()\n",
    "print(\"   üìä Bottom row: Shows actual test performance\")\n",
    "print(\"      ‚Ä¢ Circles = Correct predictions\")\n",
    "print(\"      ‚Ä¢ X marks = Incorrect predictions\")\n",
    "print(\"      ‚Ä¢ Compare error patterns between linear and RBF\")\n",
    "\n",
    "print(f\"\\nüèÜ SUMMARY OF BOUNDARY ANALYSIS:\")\n",
    "print(f\"   üìè Linear SVM: {'Simple' if sum(svm_linear.n_support_) < len(X_train) * 0.3 else 'Complex'} boundary with {sum(svm_linear.n_support_)} support vectors\")\n",
    "print(f\"   üåÄ RBF SVM: {'Complex' if sum(svm_rbf.n_support_) > sum(svm_linear.n_support_) else 'Simple'} boundary with {sum(svm_rbf.n_support_)} support vectors\")\n",
    "print(f\"   üéØ Both models achieve {'similar' if abs(accuracy - accuracy_rbf) < 0.05 else 'different'} accuracy levels\")\n",
    "print(f\"   üí° Choose based on interpretability vs flexibility trade-off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1195f7",
   "metadata": {},
   "source": [
    "## üß† Support Vector Machines (SVM) - Complete Beginner's Guide\n",
    "\n",
    "### ü§î What is a Support Vector Machine?\n",
    "\n",
    "**Simple analogy**: Imagine you're a referee trying to draw a line to separate two teams on a field\n",
    "- **Goal**: Draw the line so it's as far as possible from both teams\n",
    "- **Best line**: The one that gives maximum space (margin) between teams\n",
    "- **Support vectors**: The closest players to the line (they \"support\" the decision)\n",
    "\n",
    "### üéØ SVM's Core Philosophy:\n",
    "\n",
    "#### **The Margin Concept**:\n",
    "```\n",
    "Team A players: ‚óè‚óè‚óè‚óè‚óè     |     ‚óã‚óã‚óã‚óã‚óã Team B players\n",
    "                          |\n",
    "                    Decision Boundary\n",
    "                    \n",
    "Maximum margin = Widest possible \"safety zone\"\n",
    "```\n",
    "\n",
    "**SVM finds the line with the BIGGEST margin between classes**\n",
    "\n",
    "### üìö sklearn.svm Module - Complete Overview:\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVC\n",
    "```\n",
    "\n",
    "#### **What's in sklearn.svm**:\n",
    "- **`SVC`**: Support Vector Classifier (for classification)\n",
    "- **`SVR`**: Support Vector Regressor (for regression) \n",
    "- **`LinearSVC`**: Linear SVM Classifier (faster for linear problems)\n",
    "- **`LinearSVR`**: Linear SVM Regressor\n",
    "- **`OneClassSVM`**: For anomaly detection\n",
    "\n",
    "### üîç SVC (Support Vector Classifier) - Every Parameter Explained:\n",
    "\n",
    "```python\n",
    "classifier = SVC(\n",
    "    kernel='linear',      # How to transform the data\n",
    "    C=1.0,               # How strict to be about errors\n",
    "    gamma='scale',       # How much influence each point has\n",
    "    probability=False,   # Whether to calculate probabilities\n",
    "    random_state=None    # For reproducible results\n",
    ")\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è Complete Parameter Guide:\n",
    "\n",
    "#### **`kernel='linear'`** - The Transformation Strategy:\n",
    "\n",
    "**What kernels do**: Transform data to make it easier to separate\n",
    "\n",
    "##### **'linear'** (What we're using):\n",
    "- **Best for**: Data that can be separated by a straight line\n",
    "- **Speed**: Fastest option\n",
    "- **Interpretability**: Easy to understand and visualize\n",
    "- **When to use**: Start here, works for many problems\n",
    "\n",
    "##### **'rbf'** (Radial Basis Function - Default):\n",
    "- **Best for**: Complex, non-linear patterns\n",
    "- **Creates**: Curved decision boundaries\n",
    "- **More flexible**: Can handle circular, spiral patterns\n",
    "- **Most popular**: Works well for most datasets\n",
    "\n",
    "##### **'poly'** (Polynomial):\n",
    "- **Best for**: Polynomial-like patterns\n",
    "- **Complexity**: Controlled by degree parameter\n",
    "- **Computational cost**: Can be expensive for high degrees\n",
    "\n",
    "##### **'sigmoid'**:\n",
    "- **Similar to**: Neural network activation\n",
    "- **Less common**: Usually rbf or linear work better\n",
    "\n",
    "#### **`C=1.0`** - The Error Tolerance Parameter:\n",
    "\n",
    "**What C controls**: Trade-off between margin size and classification errors\n",
    "\n",
    "##### **High C** (e.g., C=100):\n",
    "- **Behavior**: Very strict, tries to classify every point correctly\n",
    "- **Result**: Narrow margin, complex decision boundary\n",
    "- **Risk**: Overfitting (memorizes training data)\n",
    "- **Use when**: You have clean, reliable data\n",
    "\n",
    "##### **Low C** (e.g., C=0.1):\n",
    "- **Behavior**: More tolerant of errors, prioritizes wide margin\n",
    "- **Result**: Wide margin, simpler decision boundary  \n",
    "- **Risk**: Underfitting (too simple, misses patterns)\n",
    "- **Use when**: You have noisy data\n",
    "\n",
    "##### **Visual Example**:\n",
    "```\n",
    "Low C (C=0.1):           High C (C=100):\n",
    "‚óè‚óè‚óè   |     ‚óã‚óã‚óã         ‚óè‚óè‚óè|‚óã‚óã‚óã\n",
    "‚óè‚óè‚óè   |     ‚óã‚óã‚óã         ‚óè‚óè‚óè|‚óã‚óã‚óã\n",
    "  ‚óè   |   ‚óã             ‚óè‚óè‚óè|‚óã‚óã‚óã\n",
    "      |                      |\n",
    "Wide margin                Narrow margin\n",
    "Some errors OK             No errors allowed\n",
    "```\n",
    "\n",
    "#### **`gamma='scale'`** - Point Influence Parameter (for non-linear kernels):\n",
    "\n",
    "**What gamma controls**: How far the influence of each training point reaches\n",
    "\n",
    "##### **High gamma** (e.g., gamma=10):\n",
    "- **Effect**: Each point only influences nearby decisions\n",
    "- **Result**: Very detailed, complex boundaries\n",
    "- **Risk**: Overfitting to individual points\n",
    "\n",
    "##### **Low gamma** (e.g., gamma=0.001):\n",
    "- **Effect**: Each point influences far-away decisions\n",
    "- **Result**: Smooth, simple boundaries\n",
    "- **Risk**: Underfitting, too generalized\n",
    "\n",
    "##### **'scale'** (Default):\n",
    "- **Formula**: 1 / (n_features √ó X.var())\n",
    "- **Automatic**: Adapts to your data\n",
    "- **Good choice**: Usually works well\n",
    "\n",
    "### üéØ Why Linear Kernel for Our Example:\n",
    "\n",
    "#### **Our Data Characteristics**:\n",
    "- **2D synthetic data**: Simple, controlled\n",
    "- **Likely linearly separable**: make_classification creates clean clusters\n",
    "- **Educational purpose**: Easier to visualize and understand\n",
    "- **Fast training**: Linear is computationally efficient\n",
    "\n",
    "#### **Linear SVM Decision Process**:\n",
    "1. **Find all possible lines** that separate the classes\n",
    "2. **Calculate margin** for each line (distance to nearest points)\n",
    "3. **Choose the line** with the maximum margin\n",
    "4. **Remember support vectors** (points closest to the line)\n",
    "\n",
    "### üî¨ Mathematical Intuition (Simplified):\n",
    "\n",
    "#### **Linear SVM finds**:\n",
    "- **Equation**: w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + b = 0\n",
    "- **Where**:\n",
    "  - **w‚ÇÅ, w‚ÇÇ**: Weights that determine line orientation\n",
    "  - **x‚ÇÅ, x‚ÇÇ**: Your two features\n",
    "  - **b**: Bias that determines line position\n",
    "\n",
    "#### **Classification Rule**:\n",
    "- **If** w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + b > 0 **‚Üí** Class 1\n",
    "- **If** w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + b < 0 **‚Üí** Class 0\n",
    "- **If** w‚ÇÅ√óx‚ÇÅ + w‚ÇÇ√óx‚ÇÇ + b = 0 **‚Üí** On the boundary\n",
    "\n",
    "### üí° SVM Advantages:\n",
    "\n",
    "1. **Effective**: Works well even with small datasets\n",
    "2. **Memory efficient**: Only stores support vectors, not all training data\n",
    "3. **Versatile**: Different kernels for different problems\n",
    "4. **Robust**: Good performance even with high-dimensional data\n",
    "\n",
    "### ‚ö†Ô∏è SVM Disadvantages:\n",
    "\n",
    "1. **No probability estimates**: By default (can be enabled)\n",
    "2. **Sensitive to scaling**: Features should be normalized\n",
    "3. **Slow on large datasets**: Can be computationally expensive\n",
    "4. **Parameter tuning**: Requires experimentation with C and gamma\n",
    "\n",
    "### üîß Common SVM Patterns:\n",
    "\n",
    "#### **Start Simple**:\n",
    "```python\n",
    "# Begin with linear\n",
    "svm = SVC(kernel='linear')\n",
    "```\n",
    "\n",
    "#### **If Linear Doesn't Work**:\n",
    "```python\n",
    "# Try RBF with default parameters\n",
    "svm = SVC(kernel='rbf')\n",
    "```\n",
    "\n",
    "#### **For Probability Estimates**:\n",
    "```python\n",
    "# Enable probability calculation\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "probabilities = svm.predict_proba(X_test)\n",
    "```\n",
    "\n",
    "**Remember**: SVM is like finding the fairest possible dividing line - one that stays as far away as possible from both sides!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä COMPREHENSIVE MODEL COMPARISON AND ANALYSIS\n",
    "# ==============================================\n",
    "\n",
    "# Let's create a comprehensive comparison of both SVM models we've built\n",
    "\n",
    "print(\"üìä COMPREHENSIVE SVM MODEL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comprehensive performance metrics\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_evaluation(model, X_test, y_test, model_name):\n",
    "    \"\"\"Generate comprehensive evaluation metrics for a model\"\"\"\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Basic metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Advanced metrics\n",
    "    if y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, y_proba)\n",
    "    else:\n",
    "        auc_score = None\n",
    "    \n",
    "    # Confusion matrix components\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Additional metrics\n",
    "    specificity = tn / (tn + fp)  # True Negative Rate\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall (Sensitivity)': recall,\n",
    "        'Specificity': specificity,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc_score,\n",
    "        'NPV': npv,\n",
    "        'True Positives': tp,\n",
    "        'True Negatives': tn,\n",
    "        'False Positives': fp,\n",
    "        'False Negatives': fn,\n",
    "        'Support Vectors': sum(model.n_support_) if hasattr(model, 'n_support_') else 'N/A'\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "linear_metrics = comprehensive_evaluation(svm_linear, X_test, y_test, 'Linear SVM')\n",
    "rbf_metrics = comprehensive_evaluation(svm_rbf, X_test, y_test, 'RBF SVM')\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame([linear_metrics, rbf_metrics])\n",
    "comparison_df = comparison_df.set_index('Model')\n",
    "\n",
    "print(\"üìã DETAILED PERFORMANCE COMPARISON:\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Identify winner for each metric\n",
    "print(f\"\\nüèÜ METRIC-BY-METRIC WINNERS:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "metrics_to_compare = ['Accuracy', 'Precision', 'Recall (Sensitivity)', 'Specificity', 'F1-Score', 'AUC']\n",
    "for metric in metrics_to_compare:\n",
    "    if comparison_df.loc['Linear SVM', metric] > comparison_df.loc['RBF SVM', metric]:\n",
    "        winner = \"Linear SVM\"\n",
    "        diff = comparison_df.loc['Linear SVM', metric] - comparison_df.loc['RBF SVM', metric]\n",
    "    elif comparison_df.loc['RBF SVM', metric] > comparison_df.loc['Linear SVM', metric]:\n",
    "        winner = \"RBF SVM\"\n",
    "        diff = comparison_df.loc['RBF SVM', metric] - comparison_df.loc['Linear SVM', metric]\n",
    "    else:\n",
    "        winner = \"Tie\"\n",
    "        diff = 0\n",
    "    \n",
    "    print(f\"{metric:<20}: {winner:<12} (Œî = {diff:+.4f})\")\n",
    "\n",
    "# Statistical significance test (McNemar's test for paired predictions)\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def mcnemar_test(y_true, y_pred1, y_pred2):\n",
    "    \"\"\"Perform McNemar's test to check if difference is statistically significant\"\"\"\n",
    "    # Create contingency table\n",
    "    correct1 = (y_true == y_pred1)\n",
    "    correct2 = (y_true == y_pred2)\n",
    "    \n",
    "    # Cases where models disagree\n",
    "    model1_correct_model2_wrong = np.sum(correct1 & ~correct2)\n",
    "    model1_wrong_model2_correct = np.sum(~correct1 & correct2)\n",
    "    \n",
    "    # McNemar's test statistic\n",
    "    if (model1_correct_model2_wrong + model1_wrong_model2_correct) == 0:\n",
    "        return None, None  # No disagreements\n",
    "    \n",
    "    chi2_stat = (abs(model1_correct_model2_wrong - model1_wrong_model2_correct) - 1)**2 / (model1_correct_model2_wrong + model1_wrong_model2_correct)\n",
    "    p_value = 1 - chi2.cdf(chi2_stat, 1)\n",
    "    \n",
    "    return chi2_stat, p_value\n",
    "\n",
    "# Perform McNemar's test\n",
    "chi2_stat, p_value = mcnemar_test(y_test, y_pred, y_pred_rbf)\n",
    "\n",
    "print(f\"\\nüî¨ STATISTICAL SIGNIFICANCE TEST (McNemar's Test):\")\n",
    "print(\"=\" * 55)\n",
    "if chi2_stat is not None:\n",
    "    print(f\"   œá¬≤ statistic: {chi2_stat:.4f}\")\n",
    "    print(f\"   p-value: {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"   ‚úÖ Difference is statistically significant (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Difference is NOT statistically significant (p ‚â• 0.05)\")\n",
    "else:\n",
    "    print(\"   ‚ÑπÔ∏è  Models make identical predictions - no statistical test needed\")\n",
    "\n",
    "# ROC Curve Comparison\n",
    "if hasattr(svm_linear, 'predict_proba') and hasattr(svm_rbf, 'predict_proba'):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # ROC Curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    # Linear SVM ROC\n",
    "    y_proba_linear = svm_linear.predict_proba(X_test)[:, 1]\n",
    "    fpr_linear, tpr_linear, _ = roc_curve(y_test, y_proba_linear)\n",
    "    auc_linear = roc_auc_score(y_test, y_proba_linear)\n",
    "    \n",
    "    # RBF SVM ROC\n",
    "    y_proba_rbf = svm_rbf.predict_proba(X_test)[:, 1]\n",
    "    fpr_rbf, tpr_rbf, _ = roc_curve(y_test, y_proba_rbf)\n",
    "    auc_rbf = roc_auc_score(y_test, y_proba_rbf)\n",
    "    \n",
    "    plt.plot(fpr_linear, tpr_linear, 'b-', linewidth=2, label=f'Linear SVM (AUC = {auc_linear:.3f})')\n",
    "    plt.plot(fpr_rbf, tpr_rbf, 'r-', linewidth=2, label=f'RBF SVM (AUC = {auc_rbf:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision-Recall Curves\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    precision_linear, recall_linear, _ = precision_recall_curve(y_test, y_proba_linear)\n",
    "    precision_rbf, recall_rbf, _ = precision_recall_curve(y_test, y_proba_rbf)\n",
    "    \n",
    "    plt.plot(recall_linear, precision_linear, 'b-', linewidth=2, label='Linear SVM')\n",
    "    plt.plot(recall_rbf, precision_rbf, 'r-', linewidth=2, label='RBF SVM')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Model complexity analysis\n",
    "print(f\"\\n‚öôÔ∏è  MODEL COMPLEXITY ANALYSIS:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Support Vector Usage:\")\n",
    "print(f\"   Linear SVM: {sum(svm_linear.n_support_):3d} / {X_train.shape[0]} ({sum(svm_linear.n_support_)/X_train.shape[0]:.1%})\")\n",
    "print(f\"   RBF SVM:    {sum(svm_rbf.n_support_):3d} / {X_train.shape[0]} ({sum(svm_rbf.n_support_)/X_train.shape[0]:.1%})\")\n",
    "print()\n",
    "print(f\"Model Interpretation:\")\n",
    "if sum(svm_linear.n_support_) < sum(svm_rbf.n_support_):\n",
    "    print(\"   üìä Linear SVM uses fewer support vectors ‚Üí Simpler model\")\n",
    "    print(\"   üéØ RBF SVM uses more support vectors ‚Üí More complex model\")\n",
    "else:\n",
    "    print(\"   üìä Both models have similar complexity\")\n",
    "\n",
    "print(f\"\\nTraining Efficiency:\")\n",
    "print(f\"   Linear SVM: {training_time:.4f} seconds\")\n",
    "print(f\"   RBF SVM:    {training_time_rbf:.4f} seconds\")\n",
    "print(f\"   Speed ratio: {training_time_rbf/training_time:.2f}x {'slower' if training_time_rbf > training_time else 'faster'} for RBF\")\n",
    "\n",
    "# Final recommendation\n",
    "accuracy_diff = abs(accuracy_rbf - accuracy)\n",
    "complexity_diff = abs(sum(svm_rbf.n_support_) - sum(svm_linear.n_support_))\n",
    "\n",
    "print(f\"\\nüéØ FINAL MODEL SELECTION RECOMMENDATION:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if accuracy_diff < 0.02:  # Similar performance\n",
    "    print(\"   üìä Both models show similar accuracy\")\n",
    "    if sum(svm_linear.n_support_) < sum(svm_rbf.n_support_):\n",
    "        print(\"   ‚úÖ RECOMMENDATION: Linear SVM\")\n",
    "        print(\"   üí° Reasons: Simpler, faster, more interpretable\")\n",
    "    else:\n",
    "        print(\"   ‚öñÔ∏è  RECOMMENDATION: Either model is suitable\")\n",
    "        print(\"   üí° Choose based on interpretability vs flexibility needs\")\n",
    "elif accuracy_rbf > accuracy:\n",
    "    print(\"   üìà RBF SVM shows better accuracy\")\n",
    "    if accuracy_diff > 0.05:\n",
    "        print(\"   ‚úÖ RECOMMENDATION: RBF SVM\")\n",
    "        print(\"   üí° Reasons: Significantly better performance justifies complexity\")\n",
    "    else:\n",
    "        print(\"   ‚öñÔ∏è  RECOMMENDATION: Consider both options\")\n",
    "        print(\"   üí° Small improvement may not justify added complexity\")\n",
    "else:\n",
    "    print(\"   üìà Linear SVM shows better accuracy\")\n",
    "    print(\"   ‚úÖ RECOMMENDATION: Linear SVM\")\n",
    "    print(\"   üí° Reasons: Better performance AND simpler model\")\n",
    "\n",
    "print(f\"\\nüìö KEY TAKEAWAYS:\")\n",
    "print(f\"   ‚Ä¢ Linear SVM: Best for interpretability and speed\")\n",
    "print(f\"   ‚Ä¢ RBF SVM: Best for complex, non-linear patterns\")\n",
    "print(f\"   ‚Ä¢ Always compare multiple models on your specific dataset\")\n",
    "print(f\"   ‚Ä¢ Consider the trade-off between accuracy and complexity\")\n",
    "print(f\"   ‚Ä¢ Use cross-validation for more robust model selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d1df16",
   "metadata": {},
   "source": [
    "## Creating the SVM classifier\n",
    "\n",
    "```python\n",
    "classifier = SVC(kernel='linear')\n",
    "```\n",
    "\n",
    "**What's happening here:**\n",
    "I'm creating an SVM (Support Vector Machine) classifier with a linear kernel. Think of this as setting up a \"line-drawing machine\" that will find the best possible line to separate my two classes.\n",
    "\n",
    "**Why SVC:**\n",
    "SVC stands for Support Vector Classifier. It's the sklearn implementation of SVM.\n",
    "\n",
    "**Why kernel='linear':**\n",
    "Since my data is 2D and probably linearly separable (because make_classification usually creates clean data), a straight line should be able to separate the classes pretty well. Linear is also the simplest to understand and visualize.\n",
    "\n",
    "**What the linear kernel does:**\n",
    "It will try to find a straight line (in 2D) that separates class 0 from class 1, with the biggest possible \"margin\" (empty space) between the line and the nearest points from each class.\n",
    "\n",
    "**Other kernels I could use:**\n",
    "- 'rbf': For curved boundaries (more complex)\n",
    "- 'poly': For polynomial boundaries  \n",
    "- 'sigmoid': For S-shaped boundaries\n",
    "\n",
    "But linear is perfect for learning since I can actually see what it's doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94de94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;linear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;scale&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üéì CHAPTER SUMMARY: WHAT WE LEARNED ABOUT SVM\n",
    "# =============================================\n",
    "\n",
    "print(\"üéì COMPREHENSIVE SVM LEARNING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üß† CORE SVM CONCEPTS WE MASTERED:\")\n",
    "print(\"   1. üìè Maximum Margin Principle\")\n",
    "print(\"      ‚Ä¢ SVM finds the decision boundary with largest margin\")\n",
    "print(\"      ‚Ä¢ Margin = distance between boundary and closest points\")\n",
    "print(\"      ‚Ä¢ Maximizes generalization to unseen data\")\n",
    "print()\n",
    "print(\"   2. üéØ Support Vectors\")\n",
    "print(f\"      ‚Ä¢ Critical points that define the decision boundary\")\n",
    "print(f\"      ‚Ä¢ Linear SVM used {sum(svm_linear.n_support_)} support vectors\")\n",
    "print(f\"      ‚Ä¢ RBF SVM used {sum(svm_rbf.n_support_)} support vectors\")\n",
    "print(f\"      ‚Ä¢ Only these points matter for predictions!\")\n",
    "print()\n",
    "print(\"   3. üîß Hyperparameters\")\n",
    "print(\"      ‚Ä¢ C parameter: Controls overfitting vs underfitting\")\n",
    "print(\"      ‚Ä¢ kernel: Determines boundary shape (linear vs curved)\")\n",
    "print(\"      ‚Ä¢ gamma (RBF): Controls influence radius of each point\")\n",
    "print()\n",
    "print(\"   4. ‚öñÔ∏è Bias-Variance Trade-off\")\n",
    "print(\"      ‚Ä¢ Linear SVM: Lower variance, potential higher bias\")\n",
    "print(\"      ‚Ä¢ RBF SVM: Higher variance, potential lower bias\")\n",
    "print(\"      ‚Ä¢ Need to balance based on dataset complexity\")\n",
    "\n",
    "print(f\"\\nüìä PRACTICAL RESULTS FROM OUR EXPERIMENT:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features, 2 classes\")\n",
    "print(f\"Train/Test Split: {X_train.shape[0]}/{X_test.shape[0]} samples\")\n",
    "print()\n",
    "print(\"Linear SVM Performance:\")\n",
    "print(f\"   ‚úÖ Accuracy: {accuracy:.1%}\")\n",
    "print(f\"   ‚ö° Training time: {training_time:.4f} seconds\")\n",
    "print(f\"   üéØ Support vectors: {sum(svm_linear.n_support_)} ({sum(svm_linear.n_support_)/X_train.shape[0]:.1%} of training data)\")\n",
    "print(f\"   üìè Boundary type: Straight lines only\")\n",
    "print()\n",
    "print(\"RBF SVM Performance:\")\n",
    "print(f\"   ‚úÖ Accuracy: {accuracy_rbf:.1%}\")\n",
    "print(f\"   ‚ö° Training time: {training_time_rbf:.4f} seconds\")\n",
    "print(f\"   üéØ Support vectors: {sum(svm_rbf.n_support_)} ({sum(svm_rbf.n_support_)/X_train.shape[0]:.1%} of training data)\")\n",
    "print(f\"   üåÄ Boundary type: Curved, flexible boundaries\")\n",
    "\n",
    "print(f\"\\nüîç KEY INSIGHTS DISCOVERED:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Generate insights based on actual results\n",
    "if accuracy_rbf > accuracy + 0.02:\n",
    "    print(\"   üìà RBF kernel provided meaningful improvement\")\n",
    "    print(\"   üí° This dataset benefits from non-linear boundaries\")\n",
    "elif accuracy > accuracy_rbf + 0.02:\n",
    "    print(\"   üìà Linear kernel was surprisingly effective\")\n",
    "    print(\"   üí° This dataset is more linearly separable than expected\")\n",
    "else:\n",
    "    print(\"   ‚öñÔ∏è Both kernels performed similarly\")\n",
    "    print(\"   üí° Dataset complexity is at the boundary between linear/non-linear\")\n",
    "\n",
    "if sum(svm_rbf.n_support_) > sum(svm_linear.n_support_) * 1.5:\n",
    "    print(\"   üî¢ RBF SVM required significantly more support vectors\")\n",
    "    print(\"   ‚ö†Ô∏è Indicates higher model complexity and potential overfitting risk\")\n",
    "else:\n",
    "    print(\"   üî¢ Both models used similar numbers of support vectors\")\n",
    "    print(\"   ‚úÖ Good sign for model stability\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è PRACTICAL SKILLS DEVELOPED:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"   ‚úÖ Created and trained SVM models with scikit-learn\")\n",
    "print(\"   ‚úÖ Compared linear vs RBF kernels systematically\")\n",
    "print(\"   ‚úÖ Evaluated models using multiple metrics\")\n",
    "print(\"   ‚úÖ Visualized decision boundaries and support vectors\")\n",
    "print(\"   ‚úÖ Interpreted model predictions and confidence scores\")\n",
    "print(\"   ‚úÖ Analyzed model complexity and performance trade-offs\")\n",
    "print(\"   ‚úÖ Applied statistical tests for model comparison\")\n",
    "\n",
    "print(f\"\\nüéØ WHEN TO USE EACH SVM TYPE:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"üî≤ Linear SVM - Choose when:\")\n",
    "print(\"   ‚Ä¢ You need interpretable results\")\n",
    "print(\"   ‚Ä¢ Training/prediction speed is critical\")\n",
    "print(\"   ‚Ä¢ You have high-dimensional data\")\n",
    "print(\"   ‚Ä¢ You suspect data is linearly separable\")\n",
    "print(\"   ‚Ä¢ You want to avoid overfitting\")\n",
    "print()\n",
    "print(\"üåÄ RBF SVM - Choose when:\")\n",
    "print(\"   ‚Ä¢ You have complex, non-linear patterns\")\n",
    "print(\"   ‚Ä¢ Accuracy is more important than interpretability\")\n",
    "print(\"   ‚Ä¢ You have sufficient training data\")\n",
    "print(\"   ‚Ä¢ You can afford longer training times\")\n",
    "print(\"   ‚Ä¢ Linear SVM shows poor performance\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è COMMON PITFALLS TO AVOID:\")\n",
    "print(\"=\" * 40)\n",
    "print(\"   1. üéØ Forgetting to scale features\")\n",
    "print(\"      ‚Ä¢ SVM is sensitive to feature scales\")\n",
    "print(\"      ‚Ä¢ Always standardize or normalize your data\")\n",
    "print()\n",
    "print(\"   2. ‚öñÔ∏è Not tuning hyperparameters\")\n",
    "print(\"      ‚Ä¢ Default parameters may not be optimal\")\n",
    "print(\"      ‚Ä¢ Use GridSearch or RandomSearch for tuning\")\n",
    "print()\n",
    "print(\"   3. üìä Ignoring class imbalance\")\n",
    "print(\"      ‚Ä¢ Use class_weight='balanced' for imbalanced data\")\n",
    "print(\"      ‚Ä¢ Or adjust sample weights manually\")\n",
    "print()\n",
    "print(\"   4. üîÆ Overfitting with RBF kernel\")\n",
    "print(\"      ‚Ä¢ High gamma values can cause overfitting\")\n",
    "print(\"      ‚Ä¢ Always validate on unseen data\")\n",
    "\n",
    "print(f\"\\nüîó CONNECTIONS TO OTHER ML CONCEPTS:\")\n",
    "print(\"=\" * 45)\n",
    "print(\"   üìè Geometry: SVM uses geometric intuition\")\n",
    "print(\"   üìä Optimization: Quadratic programming under the hood\")\n",
    "print(\"   üéØ Regularization: C parameter provides L2 regularization\")\n",
    "print(\"   üîÄ Kernel Methods: Foundation for many other algorithms\")\n",
    "print(\"   üìà Feature Engineering: Kernels implicitly create features\")\n",
    "print(\"   ‚öñÔ∏è Bias-Variance: Clear example of this fundamental trade-off\")\n",
    "\n",
    "print(f\"\\nüéØ REAL-WORLD APPLICATIONS WHERE SVM EXCELS:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"   üìß Text Classification (spam detection, sentiment analysis)\")\n",
    "print(\"   üß¨ Bioinformatics (gene classification, protein structure)\")\n",
    "print(\"   üñºÔ∏è Image Recognition (face detection, object classification)\")\n",
    "print(\"   üí∞ Finance (fraud detection, credit scoring)\")\n",
    "print(\"   üî¨ Scientific Research (pattern recognition in data)\")\n",
    "print(\"   üìä Market Analysis (customer segmentation)\")\n",
    "\n",
    "print(f\"\\nüìö THEORETICAL FOUNDATIONS COVERED:\")\n",
    "print(\"=\" * 45)\n",
    "print(\"   üßÆ Mathematical optimization (margin maximization)\")\n",
    "print(\"   üìê Geometric interpretation (hyperplanes and margins)\")\n",
    "print(\"   üî¢ Statistical learning theory (VC dimension, PAC learning)\")\n",
    "print(\"   üåÄ Kernel methods (implicit feature space transformation)\")\n",
    "print(\"   üìä Regularization theory (preventing overfitting)\")\n",
    "\n",
    "print(f\"\\nüöÄ NEXT STEPS IN YOUR SVM JOURNEY:\")\n",
    "print(\"=\" * 45)\n",
    "print(\"   1. üîß Learn hyperparameter tuning (GridSearchCV)\")\n",
    "print(\"   2. üåÄ Explore other kernels (polynomial, sigmoid, custom)\")\n",
    "print(\"   3. üìä Study multiclass SVM strategies\")\n",
    "print(\"   4. ‚öñÔ∏è Learn about class imbalance handling\")\n",
    "print(\"   5. üéØ Practice on real-world datasets\")\n",
    "print(\"   6. üìà Explore SVM for regression (SVR)\")\n",
    "print(\"   7. üß† Understand the mathematical foundations deeper\")\n",
    "print(\"   8. üîó Learn about ensemble methods with SVM\")\n",
    "\n",
    "print(f\"\\n‚ú® CONGRATULATIONS!\")\n",
    "print(\"=\" * 30)\n",
    "print(\"üéâ You've successfully completed SVM Basic Classification!\")\n",
    "print(\"üß† You now understand one of the most powerful ML algorithms\")\n",
    "print(\"üõ†Ô∏è You have practical skills to apply SVM to real problems\")\n",
    "print(\"üìà You can make informed decisions about when to use SVM\")\n",
    "print(\"üîç You can interpret and validate SVM results properly\")\n",
    "print()\n",
    "print(\"üåü Keep exploring and applying these concepts to new datasets!\")\n",
    "print(\"üìö The journey in machine learning continues with more exciting algorithms ahead!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead0b17",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "\n",
    "```python\n",
    "classifier.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**What's happening:**\n",
    "This is where the actual learning happens. I'm showing the classifier all my training data (X_train) and the correct answers (y_train), and it's figuring out the best line to separate them.\n",
    "\n",
    "**The SVM process:**\n",
    "1. Look at all 700 training points\n",
    "2. Try different possible lines that could separate class 0 from class 1\n",
    "3. For each line, calculate how far away the closest points are (the \"margin\")\n",
    "4. Pick the line with the biggest margin\n",
    "5. Remember which points are closest to this line (these become the \"support vectors\")\n",
    "\n",
    "**Why this matters:**\n",
    "The SVM doesn't just find any line that works - it finds the line that's most likely to work on new, unseen data. By maximizing the margin, it creates the most \"confident\" boundary.\n",
    "\n",
    "**What I get back:**\n",
    "The classifier is now trained and ready to make predictions on new data. It has learned the decision boundary and stored the support vectors it needs to make classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4de81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SVM decision boundary\n",
    "def plot_svm_decision_boundary(X, y, model, title=\"SVM Decision Boundary\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create a mesh to plot the decision boundary\n",
    "    h = 0.01\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Make predictions on the mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundary\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4, cmap=plt.cm.RdYlBu)\n",
    "    \n",
    "    # Plot the data points\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors='black')\n",
    "    \n",
    "    # Plot support vectors if available\n",
    "    if hasattr(model, 'support_vectors_'):\n",
    "        plt.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1],\n",
    "                   s=100, facecolors='none', edgecolors='black', linewidth=2,\n",
    "                   label='Support Vectors')\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.show()\n",
    "\n",
    "# Plot decision boundary for the trained classifier\n",
    "plot_svm_decision_boundary(X_train, y_train, classifier, \"SVM Linear Kernel Decision Boundary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ffdbd",
   "metadata": {},
   "source": [
    "### Understanding the SVM decision boundary:\n",
    "\n",
    "**What this visualization shows:**\n",
    "- **Background colors**: The decision regions (red vs blue areas)\n",
    "- **Decision boundary**: The line where colors change\n",
    "- **Data points**: Training data with true class colors\n",
    "- **Support vectors**: Points with black circles (if visible)\n",
    "\n",
    "**Key insights:**\n",
    "- **Linear boundary**: Straight line separating classes\n",
    "- **Support vectors**: Only these points determine the boundary\n",
    "- **Margin**: Empty space around the decision line\n",
    "- **Misclassifications**: Points on the wrong side of the boundary\n",
    "\n",
    "**What makes SVM special:**\n",
    "- The decision boundary only depends on support vectors\n",
    "- Other points could be removed without changing the boundary\n",
    "- SVM finds the boundary with maximum margin (safest separation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f1ce59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.23865329, 0.20880704]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e88f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0addb0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3832a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       135\n",
      "           1       0.87      0.82      0.84       165\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.83      0.83      0.83       300\n",
      "weighted avg       0.84      0.83      0.83       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "853b0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  21]\n",
      " [ 29 136]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e15221e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb9446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning with svm-sypport vector clasifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={\n",
    "    'C':[1,2,3,10,50,100],\n",
    "    'gamma':[0.1,0.2,0.003,0.001],\n",
    "    'kernel':['linear'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779e0bd",
   "metadata": {},
   "source": [
    "## üîç GridSearchCV - The Ultimate Parameter Optimizer (Complete Guide)\n",
    "\n",
    "### ü§î What is GridSearchCV and Why Do We Need It?\n",
    "\n",
    "**Simple analogy**: Like a chef trying different combinations of ingredients to make the perfect recipe\n",
    "- **Without GridSearch**: Try random combinations, hope for the best\n",
    "- **With GridSearch**: Systematically try ALL combinations, find the best one\n",
    "\n",
    "### üéØ The Hyperparameter Problem:\n",
    "\n",
    "#### **The Challenge**:\n",
    "Your SVM model has settings (hyperparameters) that dramatically affect performance:\n",
    "- **C**: How strict should the model be?\n",
    "- **gamma**: How complex should the decision boundary be?\n",
    "- **kernel**: What transformation should we use?\n",
    "\n",
    "#### **The Manual Approach** (Tedious):\n",
    "```python\n",
    "# Try C=1\n",
    "svm1 = SVC(C=1, gamma=0.1)\n",
    "svm1.fit(X_train, y_train)\n",
    "score1 = svm1.score(X_test, y_test)  # Gets 85%\n",
    "\n",
    "# Try C=10  \n",
    "svm2 = SVC(C=10, gamma=0.1)\n",
    "svm2.fit(X_train, y_train)\n",
    "score2 = svm2.score(X_test, y_test)  # Gets 92%\n",
    "\n",
    "# Try C=100...\n",
    "# This would take forever!\n",
    "```\n",
    "\n",
    "#### **The GridSearchCV Approach** (Smart):\n",
    "```python\n",
    "# Try ALL combinations automatically\n",
    "params = {'C': [1, 10, 100], 'gamma': [0.1, 0.01]}\n",
    "grid = GridSearchCV(SVC(), params)\n",
    "grid.fit(X_train, y_train)\n",
    "# Best combination found automatically!\n",
    "```\n",
    "\n",
    "### üìö Understanding GridSearchCV - Complete Function Breakdown:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=SVC(),          # The model to optimize\n",
    "    param_grid=params,        # Parameter combinations to try\n",
    "    cv=10,                    # Cross-validation folds\n",
    "    verbose=5,                # How much output to show\n",
    "    scoring='accuracy',       # How to measure performance\n",
    "    n_jobs=-1                 # How many CPU cores to use\n",
    ")\n",
    "```\n",
    "\n",
    "### üõ†Ô∏è Every Parameter Explained in Detail:\n",
    "\n",
    "#### **`estimator=SVC()`** - The Model to Optimize:\n",
    "- **What it is**: The machine learning algorithm you want to tune\n",
    "- **Our example**: SVC() - Support Vector Classifier\n",
    "- **Other examples**: RandomForestClassifier(), LogisticRegression()\n",
    "- **Important**: Use default parameters, GridSearch will change them\n",
    "\n",
    "#### **`param_grid=params`** - The Parameter Space:\n",
    "\n",
    "**Our parameter grid**:\n",
    "```python\n",
    "params = {\n",
    "    'C': [1, 2, 3, 10, 50, 100],           # 6 values\n",
    "    'gamma': [0.1, 0.2, 0.003, 0.001],     # 4 values  \n",
    "    'kernel': ['linear'],                   # 1 value\n",
    "}\n",
    "```\n",
    "\n",
    "##### **Total Combinations**: 6 √ó 4 √ó 1 = 24 different models to try!\n",
    "\n",
    "##### **What each combination means**:\n",
    "```\n",
    "Model 1: C=1, gamma=0.1, kernel='linear'\n",
    "Model 2: C=1, gamma=0.2, kernel='linear'  \n",
    "Model 3: C=1, gamma=0.003, kernel='linear'\n",
    "...\n",
    "Model 24: C=100, gamma=0.001, kernel='linear'\n",
    "```\n",
    "\n",
    "##### **Parameter Grid Strategies**:\n",
    "\n",
    "**Conservative Grid** (faster):\n",
    "```python\n",
    "params = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [0.1, 0.01]\n",
    "}\n",
    "# Only 6 combinations\n",
    "```\n",
    "\n",
    "**Comprehensive Grid** (thorough):\n",
    "```python\n",
    "params = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "# 40 combinations!\n",
    "```\n",
    "\n",
    "#### **`cv=10`** - Cross-Validation Folds:\n",
    "\n",
    "**What Cross-Validation Does**:\n",
    "Instead of just using train/test split once, it does it multiple times for reliability\n",
    "\n",
    "##### **10-Fold Cross-Validation Process**:\n",
    "1. **Split training data into 10 pieces**\n",
    "2. **For each parameter combination**:\n",
    "   - Train on 9 pieces, test on 1 piece (repeat 10 times)\n",
    "   - Average the 10 scores\n",
    "3. **Pick combination with best average score**\n",
    "\n",
    "##### **Visual Example**:\n",
    "```\n",
    "Fold 1: Train[‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ°] Test[‚ñ°]\n",
    "Fold 2: Train[‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†] Test[‚ñ°]  \n",
    "Fold 3: Train[‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†] Test[‚ñ°]\n",
    "...\n",
    "Fold 10: Train[‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†] Test[‚ñ°]\n",
    "\n",
    "Average all 10 test scores = Final score for this parameter combo\n",
    "```\n",
    "\n",
    "##### **CV Value Guidelines**:\n",
    "- **cv=5**: Fast, good for large datasets\n",
    "- **cv=10**: Standard choice, good balance\n",
    "- **cv=20**: Very thorough, slow\n",
    "- **cv=len(X_train)**: Leave-one-out (very slow)\n",
    "\n",
    "#### **`verbose=5`** - Output Detail Level:\n",
    "\n",
    "**Controls how much information is printed during search**:\n",
    "- **verbose=0**: Silent (no output)\n",
    "- **verbose=1**: Basic progress\n",
    "- **verbose=2**: More details\n",
    "- **verbose=5**: Maximum details (what we're using)\n",
    "\n",
    "**Sample output with verbose=5**:\n",
    "```\n",
    "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
    "[CV] C=1, gamma=0.1, kernel=linear ........................\n",
    "[CV] ........................ C=1, gamma=0.1, kernel=linear, score=0.857, total=   0.0s\n",
    "[CV] C=1, gamma=0.2, kernel=linear ........................\n",
    "```\n",
    "\n",
    "#### **`scoring='accuracy'`** - Performance Metric:\n",
    "\n",
    "**How to measure which combination is \"best\"**:\n",
    "- **'accuracy'**: Percentage of correct predictions (default for classification)\n",
    "- **'precision'**: How many predicted positives were actually positive\n",
    "- **'recall'**: How many actual positives were found\n",
    "- **'f1'**: Harmonic mean of precision and recall\n",
    "- **'roc_auc'**: Area under ROC curve\n",
    "\n",
    "#### **`n_jobs=-1`** - Parallel Processing:\n",
    "- **n_jobs=1**: Use 1 CPU core (slow)\n",
    "- **n_jobs=2**: Use 2 CPU cores\n",
    "- **n_jobs=-1**: Use ALL available CPU cores (fastest)\n",
    "\n",
    "### üéØ Our Specific Parameter Choices Explained:\n",
    "\n",
    "#### **`C=[1, 2, 3, 10, 50, 100]`** - Regularization Strength:\n",
    "- **Small values (1, 2, 3)**: More regularization, simpler models\n",
    "- **Medium values (10)**: Balanced approach  \n",
    "- **Large values (50, 100)**: Less regularization, more complex models\n",
    "- **Why this range**: Covers simple to complex models\n",
    "\n",
    "#### **`gamma=[0.1, 0.2, 0.003, 0.001]`** - Kernel Coefficient:\n",
    "- **Note**: Only used for 'rbf', 'poly', 'sigmoid' kernels\n",
    "- **For linear kernel**: This parameter is ignored\n",
    "- **High values (0.1, 0.2)**: More complex boundaries\n",
    "- **Low values (0.003, 0.001)**: Smoother boundaries\n",
    "\n",
    "#### **`kernel=['linear']`** - Transformation Type:\n",
    "- **Why only linear**: Our data is likely linearly separable\n",
    "- **Educational**: Easier to understand and visualize\n",
    "- **Fast**: Linear kernels are computationally efficient\n",
    "\n",
    "### üîÑ Complete GridSearchCV Workflow:\n",
    "\n",
    "#### **Step 1**: Define parameter grid\n",
    "```python\n",
    "params = {'C': [1, 10, 100], 'gamma': [0.1, 0.01]}\n",
    "```\n",
    "\n",
    "#### **Step 2**: Create GridSearchCV object\n",
    "```python\n",
    "grid = GridSearchCV(SVC(), param_grid=params, cv=10)\n",
    "```\n",
    "\n",
    "#### **Step 3**: Fit (this does all the work)\n",
    "```python\n",
    "grid.fit(X_train, y_train)  # Tries all combinations with CV\n",
    "```\n",
    "\n",
    "#### **Step 4**: Get results\n",
    "```python\n",
    "print(grid.best_params_)      # Best parameter combination\n",
    "print(grid.best_score_)       # Best cross-validation score\n",
    "print(grid.best_estimator_)   # Best model (ready to use)\n",
    "```\n",
    "\n",
    "#### **Step 5**: Use best model\n",
    "```python\n",
    "y_pred = grid.predict(X_test)  # Automatically uses best model\n",
    "```\n",
    "\n",
    "### üé≤ Advanced GridSearchCV Features:\n",
    "\n",
    "#### **Multiple Grids**:\n",
    "```python\n",
    "param_grid = [\n",
    "    {'kernel': ['linear'], 'C': [1, 10, 100]},\n",
    "    {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.1, 0.01]}\n",
    "]\n",
    "```\n",
    "\n",
    "#### **Custom Scoring**:\n",
    "```python\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "grid = GridSearchCV(SVC(), params, scoring=f1_scorer)\n",
    "```\n",
    "\n",
    "### üí° Best Practices:\n",
    "\n",
    "1. **Start with small grids**: Test the approach quickly\n",
    "2. **Expand gradually**: Add more parameter values\n",
    "3. **Use appropriate CV**: Larger datasets can use smaller cv values\n",
    "4. **Monitor overfitting**: Best CV score vs. final test score should be similar\n",
    "5. **Save time**: Use n_jobs=-1 for parallel processing\n",
    "\n",
    "### ‚è±Ô∏è Computational Cost:\n",
    "\n",
    "**Total models trained**: (param combinations) √ó (CV folds)\n",
    "**Our example**: 24 combinations √ó 10 folds = 240 individual SVM models!\n",
    "\n",
    "**Time estimation**:\n",
    "- Each SVM: ~0.1 seconds\n",
    "- Total time: ~24 seconds\n",
    "- With parallel processing: ~6 seconds (on 4-core machine)\n",
    "\n",
    "**Remember**: GridSearchCV is like having a tireless assistant who tries every possible combination to find the perfect settings for your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c300d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(SVC(),param_grid=params,cv=10,verbose=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbe9fc3",
   "metadata": {},
   "source": [
    "## Setting up GridSearchCV\n",
    "\n",
    "```python\n",
    "grid = GridSearchCV(SVC(), param_grid=params, cv=10, verbose=5)\n",
    "```\n",
    "\n",
    "**What this does:**\n",
    "Creates a \"parameter testing machine\" that will try every combination in my params dictionary and tell me which works best.\n",
    "\n",
    "**Breaking it down:**\n",
    "- `SVC()`: A fresh SVM classifier (it will create new ones for each test)\n",
    "- `param_grid=params`: Use my parameter dictionary from before\n",
    "- `cv=10`: Use 10-fold cross-validation (split training data into 10 pieces, train on 9, test on 1, repeat 10 times)\n",
    "- `verbose=5`: Show me everything that's happening (good for learning, annoying for production)\n",
    "\n",
    "**Why cv=10:**\n",
    "This means for each parameter combination, it doesn't just test once - it tests 10 times with different train/validation splits and averages the results. More reliable than a single test.\n",
    "\n",
    "**What will happen when I run fit():**\n",
    "It will test all 24 combinations (4 C values √ó 3 gamma values √ó 2 kernel types) with 10-fold CV each. That's 240 individual SVM models being trained and tested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cfac2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "[CV 1/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=1, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=1, gamma=0.1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=1, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=1, gamma=0.2, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=1, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=1, gamma=0.003, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=1, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=1, gamma=0.001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=2, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=2, gamma=0.1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=2, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=2, gamma=0.2, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=2, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=2, gamma=0.003, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=2, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=2, gamma=0.001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=3, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=3, gamma=0.1, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ....C=3, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ...C=3, gamma=0.2, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=3, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=3, gamma=0.003, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=3, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=3, gamma=0.001, kernel=linear;, score=0.786 total time=   0.0s\n",
      "[CV 1/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ...C=10, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ..C=10, gamma=0.1, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ...C=10, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ..C=10, gamma=0.2, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END .C=10, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END .C=10, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END .C=10, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END .C=10, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END .C=10, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END .C=10, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END .C=10, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END .C=10, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END .C=10, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=10, gamma=0.003, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END .C=10, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END .C=10, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END .C=10, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END .C=10, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END .C=10, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END .C=10, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END .C=10, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END .C=10, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END .C=10, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=10, gamma=0.001, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ...C=50, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ..C=50, gamma=0.1, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ...C=50, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END ..C=50, gamma=0.2, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END .C=50, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END .C=50, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END .C=50, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END .C=50, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END .C=50, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END .C=50, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END .C=50, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END .C=50, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END .C=50, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=50, gamma=0.003, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END .C=50, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END .C=50, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END .C=50, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END .C=50, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END .C=50, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END .C=50, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END .C=50, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END .C=50, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END .C=50, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=50, gamma=0.001, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=100, gamma=0.1, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=100, gamma=0.1, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END ..C=100, gamma=0.2, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END .C=100, gamma=0.2, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END C=100, gamma=0.003, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END C=100, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END C=100, gamma=0.003, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END C=100, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END C=100, gamma=0.003, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END C=100, gamma=0.003, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END C=100, gamma=0.003, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END C=100, gamma=0.003, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END C=100, gamma=0.003, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=100, gamma=0.003, kernel=linear;, score=0.800 total time=   0.0s\n",
      "[CV 1/10] END C=100, gamma=0.001, kernel=linear;, score=0.900 total time=   0.0s\n",
      "[CV 2/10] END C=100, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 3/10] END C=100, gamma=0.001, kernel=linear;, score=0.829 total time=   0.0s\n",
      "[CV 4/10] END C=100, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 5/10] END C=100, gamma=0.001, kernel=linear;, score=0.914 total time=   0.0s\n",
      "[CV 6/10] END C=100, gamma=0.001, kernel=linear;, score=0.843 total time=   0.0s\n",
      "[CV 7/10] END C=100, gamma=0.001, kernel=linear;, score=0.871 total time=   0.0s\n",
      "[CV 8/10] END C=100, gamma=0.001, kernel=linear;, score=0.757 total time=   0.0s\n",
      "[CV 9/10] END C=100, gamma=0.001, kernel=linear;, score=0.771 total time=   0.0s\n",
      "[CV 10/10] END C=100, gamma=0.001, kernel=linear;, score=0.800 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 2, 3, 10, 50, 100],\n",
       "                         &#x27;gamma&#x27;: [0.1, 0.2, 0.003, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "             verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">estimator&nbsp;</td>\n",
       "            <td class=\"value\">SVC()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">param_grid&nbsp;</td>\n",
       "            <td class=\"value\">{&#x27;C&#x27;: [1, 2, ...], &#x27;gamma&#x27;: [0.1, 0.2, ...], &#x27;kernel&#x27;: [&#x27;linear&#x27;]}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scoring&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">refit&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cv&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">pre_dispatch&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">error_score&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">return_train_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: SVC</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;linear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={'C': [1, 2, 3, 10, 50, 100],\n",
       "                         'gamma': [0.1, 0.2, 0.003, 0.001],\n",
       "                         'kernel': ['linear']},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6681a",
   "metadata": {},
   "source": [
    "## Running the parameter search\n",
    "\n",
    "```python\n",
    "grid.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**What just happened:**\n",
    "The computer just trained and tested 240 different SVM models (24 parameter combinations √ó 10 cross-validation folds each). This is where all the heavy computation happens.\n",
    "\n",
    "**The process:**\n",
    "1. Take first parameter combination (e.g., C=0.1, gamma=1, kernel='linear')\n",
    "2. Split training data into 10 folds\n",
    "3. Train SVM on 9 folds, test on 1 fold\n",
    "4. Repeat for all 10 folds, average the accuracy\n",
    "5. Move to next parameter combination\n",
    "6. Repeat until all 24 combinations are tested\n",
    "7. Pick the combination with the best average accuracy\n",
    "\n",
    "**Why this takes time:**\n",
    "Each of those 240 models needs to be trained from scratch. But it's worth it because now I know which parameters work best for my specific data.\n",
    "\n",
    "**verbose=5 output:**\n",
    "All that text that just printed out shows me exactly which combinations were tested and how well they did. Super useful for understanding what's happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2442011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('kernel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">kernel&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;linear&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('degree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">degree&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">0.1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('coef0',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">coef0&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('shrinking',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">shrinking&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('probability',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">probability&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cache_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">cache_size&nbsp;</td>\n",
       "            <td class=\"value\">200</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decision_function_shape',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decision_function_shape&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;ovr&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('break_ties',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">break_ties&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbf5fc",
   "metadata": {},
   "source": [
    "## Getting the best model\n",
    "\n",
    "```python\n",
    "grid.best_estimator_\n",
    "```\n",
    "\n",
    "**What this shows:**\n",
    "This is the actual SVM model with the best parameter combination, already trained and ready to use. It's like getting the \"winner\" of the competition.\n",
    "\n",
    "**Why this is useful:**\n",
    "Instead of having to remember which parameters worked best and manually create a new SVM with those settings, GridSearchCV gives me the complete trained model ready to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1950f26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f62ec",
   "metadata": {},
   "source": [
    "## Best parameters found\n",
    "\n",
    "```python\n",
    "grid.best_params_\n",
    "```\n",
    "\n",
    "**What this tells me:**\n",
    "These are the specific parameter values that gave the best cross-validation score. This is like getting the \"recipe\" for the best performing model.\n",
    "\n",
    "**How to read this:**\n",
    "The output shows something like `{'C': 10, 'gamma': 1, 'kernel': 'rbf'}` which means:\n",
    "- C=10 was the best regularization strength\n",
    "- gamma=1 was the best gamma value  \n",
    "- 'rbf' kernel worked better than 'linear'\n",
    "\n",
    "**Why this matters:**\n",
    "Now I know what settings work well for this type of data. If I get similar data in the future, I can start with these parameter values instead of guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0ea9967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8400000000000001)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c9f484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a133169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       135\n",
      "           1       0.87      0.82      0.84       165\n",
      "\n",
      "    accuracy                           0.83       300\n",
      "   macro avg       0.83      0.83      0.83       300\n",
      "weighted avg       0.84      0.83      0.83       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc0256ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff688317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
